Local Kafka broker
================

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

``` python
import unittest
from contextlib import asynccontextmanager

import pytest

from fastkafka.testing import ApacheKafkaBroker
```

## Kafka partition

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_testing/in_memory_broker.py#L39"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### KafkaRecord

>      KafkaRecord (topic:str='', partition:int=0,
>                   key:Union[bytes,NoneType]=None, value:bytes=b'',
>                   offset:int=0)

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_testing/in_memory_broker.py#L47"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### KafkaPartition

>      KafkaPartition (partition:int, topic:str)

Initialize self. See help(type(self)) for accurate signature.

``` python
partition_index = 0
topic = "test"
partition = KafkaPartition(partition=partition_index, topic=topic)

msgs = [b"some_msg" for _ in range(25)]

expected = [
    KafkaRecord(topic=topic, partition=partition_index, value=msg, offset=offset)
    for offset, msg in enumerate(msgs)
]

for msg in msgs:
    partition.write(msg)

for offset in [0, 10, 20]:
    actual = partition.read(offset=offset)

    assert actual == (expected[offset:], len(msgs))
```

``` python
partition_index = 0
topic = "test"
key = b"some_key"
partition = KafkaPartition(partition=partition_index, topic=topic)

msgs = [b"some_msg" for _ in range(25)]
expected = [
    KafkaRecord(
        topic=topic, partition=partition_index, value=msg, key=key, offset=offset
    )
    for offset, msg in enumerate(msgs)
]

for msg in msgs:
    partition.write(msg, key=key)

for offset in [0, 10, 20]:
    actual = partition.read(offset=offset)

    assert actual == (expected[offset:], len(msgs)), print(f"{actual} != {expected}")
```

## Kafka topic

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_testing/in_memory_broker.py#L80"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### KafkaTopic

>      KafkaTopic (topic:str, num_partitions:int=1)

Initialize self. See help(type(self)) for accurate signature.

``` python
msg = b"msg"

topic = KafkaTopic("test_topic", 1)

expected = RecordMetadata(
    topic="test_topic",
    partition=0,
    topic_partition=TopicPartition(topic="test_topic", partition=0),
    offset=0,
    timestamp=1680602752070,
    timestamp_type=0,
    log_start_offset=0,
)
actual = topic.write(msg)

assert expected == actual

expected = RecordMetadata(
    topic="test_topic",
    partition=0,
    topic_partition=TopicPartition(topic="test_topic", partition=0),
    offset=1,
    timestamp=1680602752070,
    timestamp_type=0,
    log_start_offset=0,
)
actual = topic.write(msg, key=b"123")

assert expected == actual, actual
```

``` python
topic_name = "test_topic"
msgs = [b"msg" for _ in range(1000)]
partition_num = 10

topic = KafkaTopic(topic_name, partition_num)

# write to topic
for msg in msgs:
    topic.write(msg)

# For each partition in topic check:
for partition in range(partition_num):
    topic_partition_expected = TopicPartition(topic=topic_name, partition=partition)
    topic_partition_actual, data, _ = topic.read(partition=partition, offset=0)

    # Read returns correct TopicPartition key
    assert topic_partition_actual == topic_partition_expected

    # Data is written into partition
    assert len(data) > 0
```

``` python
topic_name = "test_topic"
msgs = [b"msg" for _ in range(1000)]
partition_num = 2

topic = KafkaTopic(topic_name, partition_num)

# write to topic with defined partition
for msg in msgs:
    topic.write(msg, partition=0)

lengths = [len(topic.read(partition=i, offset=0)[1]) for i in range(partition_num)]

assert [1000, 0] == lengths
```

``` python
topic_name = "test_topic"
msgs = [b"msg" for _ in range(1000)]
partition_num = 3

topic = KafkaTopic(topic_name, partition_num)

# write to topic with defined key
for msg in msgs[:450]:
    topic.write(msg, key=b"some_key")

for msg in msgs[450:]:
    topic.write(msg, key=b"some_key443")

lengths = [len(topic.read(partition=i, offset=0)[1]) for i in range(partition_num)]

assert [0, 450, 550] == sorted(lengths)
```

## Group metadata

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_testing/in_memory_broker.py#L127"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### split_list

>      split_list (list_to_split:List[Any], split_size:int)

``` python
assert split_list([1, 2, 3, 4, 5], 1) == [[1], [2], [3], [4], [5]]
assert split_list([1, 2, 3, 4, 5], 2) == [[1, 2], [3, 4], [5]]
assert split_list([1, 2, 3, 4, 5], 3) == [[1, 2, 3], [4, 5]]
assert split_list([1, 2, 3, 4, 5], 5) == [[1, 2, 3, 4, 5]]
```

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_testing/in_memory_broker.py#L134"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### GroupMetadata

>      GroupMetadata (num_partitions:int)

Initialize self. See help(type(self)) for accurate signature.

``` python
group_meta = GroupMetadata(num_partitions=3)

# subscribe first consumer
consumer_id_1 = uuid.uuid4()
group_meta.subscribe(consumer_id_1)
# check partitions
assert group_meta.get_partitions(consumer_id_1)[0] == [0, 1, 2]

# subscribe second consumer
consumer_id_2 = uuid.uuid4()
group_meta.subscribe(consumer_id_2)
# check partitions
assert group_meta.get_partitions(consumer_id_1)[0] == [0, 1]
assert group_meta.get_partitions(consumer_id_2)[0] == [2]

# subscribe third consumer
consumer_id_3 = uuid.uuid4()
group_meta.subscribe(consumer_id_3)
# check partitions
assert group_meta.get_partitions(consumer_id_1)[0] == [0]
assert group_meta.get_partitions(consumer_id_2)[0] == [1]
assert group_meta.get_partitions(consumer_id_3)[0] == [2]

# subscribe fourth consumer
# subscribe third consumer
consumer_id_4 = uuid.uuid4()
group_meta.subscribe(consumer_id_4)
# check partitions
assert group_meta.get_partitions(consumer_id_1)[0] == [0]
assert group_meta.get_partitions(consumer_id_2)[0] == [1]
assert group_meta.get_partitions(consumer_id_3)[0] == [2]
assert group_meta.get_partitions(consumer_id_4)[0] == []  # fourth consumer is starving

# Unsubscribe one consumer
group_meta.unsubscribe(consumer_id_3)
# check partitions
assert group_meta.get_partitions(consumer_id_1)[0] == [0]
assert group_meta.get_partitions(consumer_id_2)[0] == [1]
assert group_meta.get_partitions(consumer_id_4)[0] == [2], group_meta.get_partitions(
    consumer_id_4
)

# Unsubscribe all but one consumer
group_meta.unsubscribe(consumer_id_1)
group_meta.unsubscribe(consumer_id_4)
assert group_meta.get_partitions(consumer_id_2)[0] == [0, 1, 2]
```

## Kafka broker

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_testing/in_memory_broker.py#L182"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### InMemoryBroker

>      InMemoryBroker (num_partitions:int=1)

Initialize self. See help(type(self)) for accurate signature.

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_testing/in_memory_broker.py#L265"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### InMemoryBroker.unsubscribe

>      InMemoryBroker.unsubscribe (bootstrap_server:str, topic:str, group:str,
>                                  consumer_id:uuid.UUID)

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_testing/in_memory_broker.py#L245"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### InMemoryBroker.subscribe

>      InMemoryBroker.subscribe (bootstrap_server:str, topic:str, group:str,
>                                consumer_id:uuid.UUID)

``` python
topic = "topic1"
bootstrap_server = "localhost:9092"
consumer_group = "my_group"

broker = InMemoryBroker()

with pytest.raises(KeyError):
    broker.topic_groups[(bootstrap_server, topic, consumer_group)]

consumer_id = broker.connect()

broker.subscribe(bootstrap_server, topic, consumer_group, consumer_id)
broker.topic_groups[(bootstrap_server, topic, consumer_group)]

broker.unsubscribe(bootstrap_server, topic, consumer_group, consumer_id)
```

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_testing/in_memory_broker.py#L276"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### InMemoryBroker.write

>      InMemoryBroker.write (bootstrap_server:str, topic:str, value:bytes,
>                            key:Union[bytes,NoneType]=None,
>                            partition:Union[int,NoneType]=None)

``` python
for key in [None, b"some_key"]:
    topic = "my_topic"
    bootstrap_server = "localhost:9092"
    value = b"msg"

    broker = InMemoryBroker(num_partitions=3)

    record_meta = broker.write(
        bootstrap_server=bootstrap_server, topic=topic, value=value, key=key
    )

    assert record_meta.topic == "my_topic"
    assert record_meta.offset == 0

    expected_msgs = [
        KafkaRecord(
            topic="my_topic",
            partition=record_meta.partition,
            key=key,
            value=b"msg",
            offset=0,
        )
    ]

    topic_partition, actual_msgs, new_offset = broker.topics[
        (bootstrap_server, topic)
    ].read(partition=record_meta.partition, offset=record_meta.offset)

    assert actual_msgs == expected_msgs
    assert topic_partition == record_meta.topic_partition
    assert new_offset == 1
```

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_testing/in_memory_broker.py#L296"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### InMemoryBroker.read

>      InMemoryBroker.read (bootstrap_server:str, topic:str, group:str,
>                           consumer_id:uuid.UUID, auto_offset_reset:str)

``` python
# Check subscribing and reading from empty partitions for same group

topic = "topic1"
bootstrap_server = "localhost:9092"
consumer_group = "my_group"

broker = InMemoryBroker(num_partitions=3)

consumer_id_1 = broker.connect()
broker.subscribe(bootstrap_server, topic, consumer_group, consumer_id_1)

assert broker.read(
    bootstrap_server=bootstrap_server,
    topic=topic,
    group=consumer_group,
    consumer_id=consumer_id_1,
    auto_offset_reset="latest",
) == {
    TopicPartition(topic=topic, partition=0): [],
    TopicPartition(topic=topic, partition=1): [],
    TopicPartition(topic=topic, partition=2): [],
}

consumer_id_2 = broker.connect()
broker.subscribe(bootstrap_server, topic, consumer_group, consumer_id_2)

assert broker.read(
    bootstrap_server=bootstrap_server,
    topic=topic,
    group=consumer_group,
    consumer_id=consumer_id_1,
    auto_offset_reset="latest",
) == {
    TopicPartition(topic=topic, partition=0): [],
    TopicPartition(topic=topic, partition=1): [],
}

assert broker.read(
    bootstrap_server=bootstrap_server,
    topic=topic,
    group=consumer_group,
    consumer_id=consumer_id_2,
    auto_offset_reset="latest",
) == {
    TopicPartition(topic=topic, partition=2): [],
}

broker.unsubscribe(bootstrap_server, topic, consumer_group, consumer_id_1)
assert broker.read(
    bootstrap_server=bootstrap_server,
    topic=topic,
    group=consumer_group,
    consumer_id=consumer_id_2,
    auto_offset_reset="latest",
) == {
    TopicPartition(topic=topic, partition=0): [],
    TopicPartition(topic=topic, partition=1): [],
    TopicPartition(topic=topic, partition=2): [],
}
```

``` python
# check writing to partitions

topic = "topic1"
bootstrap_server = "localhost:9092"
consumer_group = "my_group"

broker = InMemoryBroker(num_partitions=1)

consumer_id_1 = broker.connect()
broker.subscribe(bootstrap_server, topic, consumer_group, consumer_id_1)

record_meta = broker.write(bootstrap_server=bootstrap_server, topic=topic, value=b"msg")

assert record_meta.topic == topic
assert record_meta.partition == 0
assert record_meta.topic_partition == TopicPartition(topic=topic, partition=0)
assert record_meta.offset == 0

assert broker.read(
    bootstrap_server=bootstrap_server,
    topic=topic,
    consumer_id=consumer_id_1,
    group=consumer_group,
    auto_offset_reset="earliest",
) == {
    TopicPartition(topic=topic, partition=0): [
        KafkaRecord(topic=topic, partition=0, key=None, value=b"msg", offset=0)
    ]
}

broker.write(bootstrap_server=bootstrap_server, topic=topic, value=b"msg")

consumer_group_new = "another_group"

consumer_id_2 = broker.connect()
broker.subscribe(bootstrap_server, topic, consumer_group_new, consumer_id_2)

assert broker.read(
    bootstrap_server=bootstrap_server,
    topic=topic,
    consumer_id=consumer_id_2,
    group=consumer_group_new,
    auto_offset_reset="latest",
) == {TopicPartition(topic=topic, partition=0): []}

assert broker.read(
    bootstrap_server=bootstrap_server,
    topic=topic,
    consumer_id=consumer_id_1,
    group=consumer_group,
    auto_offset_reset="latest",
) == {
    TopicPartition(topic=topic, partition=0): [
        KafkaRecord(topic=topic, partition=0, key=None, value=b"msg", offset=1)
    ]
}
```

``` python
topic = "my_topic"
bootstrap_server = "localhost:9092"
group = "my_group"

in_memory_broker = InMemoryBroker()

consumer_id = in_memory_broker.connect()

with pytest.raises(KeyError) as e:
    in_memory_broker.read(
        bootstrap_server=bootstrap_server,
        topic=topic,
        group=group,
        consumer_id=consumer_id,
        auto_offset_reset="latest",
    )

in_memory_broker.subscribe(
    bootstrap_server=bootstrap_server, topic=topic, group=group, consumer_id=consumer_id
)

msg = in_memory_broker.read(
    bootstrap_server=bootstrap_server,
    topic=topic,
    group=group,
    consumer_id=consumer_id,
    auto_offset_reset="earliest",
)
assert msg == {TopicPartition(topic=topic, partition=0): []}, msg
```

with ApacheKafkaBroker(\[“my_topic"\], apply_nest_asyncio=True) as
bootstrap_servers: producer =
AIOKafkaProducer(bootstrap_servers=bootstrap_servers) await
producer.start() for \_ in range(1000): record = await
producer.send(topic=“not_my_topic", value=b"not my message") await
producer.stop()

with ApacheKafkaBroker(\[“my_topic"\], apply_nest_asyncio=True) as
bootstrap_servers: consumer = AIOKafkaConsumer(“my_topic",
bootstrap_servers=bootstrap_servers) await consumer.start()
print(“getmany()…") msg = await consumer.getmany(timeout_ms=0)
print(“exiting…") await consumer.stop()

## Consumer patching

We need to patch AIOKafkaConsumer methods so that we can redirect the
consumer to our local kafka broker.

Patched methods:

- [x] \_\_init\_\_
- [x] start
- [x] subscribe
- [x] stop
- [x] getmany

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_testing/in_memory_broker.py#L334"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### InMemoryConsumer

>      InMemoryConsumer (broker:__main__.InMemoryBroker)

Initialize self. See help(type(self)) for accurate signature.

``` python
broker = InMemoryBroker()

ConsumerClass = InMemoryConsumer(broker)

for cls in [ConsumerClass, AIOKafkaConsumer]:
    consumer = cls()
    assert consumer._auto_offset_reset == "latest"

    consumer = cls(auto_offset_reset="earliest")
    assert consumer._auto_offset_reset == "earliest", consumer._auto_offset_reset

    consumer = cls(auto_offset_reset="whatever")
    assert consumer._auto_offset_reset == "whatever"

    await consumer.stop()
```

    [ERROR] asyncio: Unclosed AIOKafkaConsumer
    consumer: <aiokafka.consumer.consumer.AIOKafkaConsumer object>
    [ERROR] asyncio: Unclosed AIOKafkaConsumer
    consumer: <aiokafka.consumer.consumer.AIOKafkaConsumer object>

Patching start so that we don’t try to start the real AIOKafkaConsumer
instance

------------------------------------------------------------------------

### start

>      start (**kwargs:Any)

``` python
broker = InMemoryBroker()

ConsumerClass = InMemoryConsumer(broker)

for cls in [ConsumerClass]:
    consumer = cls()
    await consumer.start()
    await consumer.stop()
```

    [INFO] __main__: AIOKafkaConsumer patched start() called()

Patching subscribe so that we can connect to our Local, in-memory, Kafka
broker

------------------------------------------------------------------------

### subscribe

>      subscribe (topics:List[str], **kwargs:Any)

``` python
broker = InMemoryBroker()

ConsumerClass = InMemoryConsumer(broker)
consumer = ConsumerClass()
await consumer.start()
consumer.subscribe(["my_topic"])
```

    [INFO] __main__: AIOKafkaConsumer patched start() called()
    [INFO] __main__: AIOKafkaConsumer patched subscribe() called
    [INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['my_topic']

Patching stop so that be dont break anything by calling the real
AIOKafkaConsumer stop()

------------------------------------------------------------------------

### stop

>      stop (**kwargs:Any)

``` python
broker = InMemoryBroker()

ConsumerClass = InMemoryConsumer(broker)
consumer = ConsumerClass()

await consumer.start()
consumer.subscribe(["my_topic"])
await consumer.stop()
```

    [INFO] __main__: AIOKafkaConsumer patched start() called()
    [INFO] __main__: AIOKafkaConsumer patched subscribe() called
    [INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['my_topic']
    [INFO] __main__: AIOKafkaConsumer patched stop() called

Patching getmany so that the messages are pulled from our Local,
in-memory, Kafka broker

------------------------------------------------------------------------

### getmany

>      getmany (**kwargs:Any)

``` python
broker = InMemoryBroker()

ConsumerClass = InMemoryConsumer(broker)
consumer = ConsumerClass(auto_offset_reset="latest")

await consumer.start()

consumer.subscribe(["my_topic"])
await consumer.getmany()

await consumer.stop()
```

    [INFO] __main__: AIOKafkaConsumer patched start() called()
    [INFO] __main__: AIOKafkaConsumer patched subscribe() called
    [INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['my_topic']
    [INFO] __main__: AIOKafkaConsumer patched stop() called

## Producer patching

We need to patch AIOKafkaProducer methods so that we can redirect the
producer to our local kafka broker

- [x] \_\_init\_\_
- [x] start
- [x] stop
- [x] send

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_testing/in_memory_broker.py#L436"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### InMemoryProducer

>      InMemoryProducer (broker:__main__.InMemoryBroker, **kwargs:Any)

Initialize self. See help(type(self)) for accurate signature.

``` python
producer_cls = InMemoryProducer(None)

producer = producer_cls()
assert producer._bootstrap_servers == "localhost"

producer = producer_cls(bootstrap_servers="kafka.airt.ai")
assert producer._bootstrap_servers == "kafka.airt.ai"
```

Patching AIOKafkaProducer start so that we mock the startup procedure of
AIOKafkaProducer

------------------------------------------------------------------------

### start

>      start (**kwargs:Any)

``` python
broker = InMemoryBroker()

ProducerClass = InMemoryProducer(broker)
producer = ProducerClass()

await producer.start()
```

    [INFO] __main__: AIOKafkaProducer patched start() called()

Patching AIOKafkaProducerStop so that we don’t uniintentionally try to
stop a real instance of AIOKafkaProducer

------------------------------------------------------------------------

### stop

>      stop (**kwargs:Any)

``` python
broker = InMemoryBroker()

ProducerClass = InMemoryProducer(broker)
producer = ProducerClass()

await producer.start()
await producer.stop()
```

    [INFO] __main__: AIOKafkaProducer patched start() called()
    [INFO] __main__: AIOKafkaProducer patched stop() called

Patching AIOKafkaProducer send so that we redirect sent messages to
Local, in-memory, Kafka broker

------------------------------------------------------------------------

### send

>      send (topic:str, msg:bytes, key:Union[bytes,NoneType]=None,
>            partition:Union[int,NoneType]=None, **kwargs:Any)

``` python
broker = InMemoryBroker()

ProducerClass = InMemoryProducer(broker)
producer = ProducerClass()

await producer.start()
msg_fut = await producer.send("my_topic", b"some_msg")
await msg_fut
```

    [INFO] __main__: AIOKafkaProducer patched start() called()

    RecordMetadata(topic='my_topic', partition=0, topic_partition=TopicPartition(topic='my_topic', partition=0), offset=0, timestamp=1680602752070, timestamp_type=0, log_start_offset=0)

## Add patching to InMemoryBroker

------------------------------------------------------------------------

### lifecycle

>      lifecycle ()

``` python
assert fastkafka._application.app.AIOKafkaConsumer == AIOKafkaConsumer
assert fastkafka._application.app.AIOKafkaProducer == AIOKafkaProducer

with InMemoryBroker() as broker:
    assert isinstance(fastkafka._application.app.AIOKafkaConsumer, InMemoryConsumer)
    assert isinstance(fastkafka._application.app.AIOKafkaProducer, InMemoryProducer)
    assert fastkafka._application.app.AIOKafkaConsumer().broker == broker
    assert fastkafka._application.app.AIOKafkaProducer().broker == broker

assert fastkafka._application.app.AIOKafkaConsumer == AIOKafkaConsumer
assert fastkafka._application.app.AIOKafkaProducer == AIOKafkaProducer
```

    [INFO] __main__: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!
    [INFO] __main__: InMemoryBroker starting
    [INFO] __main__: InMemoryBroker stopping

## Broker, consumer and producer integration tests

``` python
@asynccontextmanager
async def create_consumer_and_producer(
    auto_offset_reset: str = "latest",
) -> AsyncIterator[Tuple[AIOKafkaConsumer, AIOKafkaProducer]]:
    consumer = fastkafka._application.app.AIOKafkaConsumer(
        auto_offset_reset=auto_offset_reset
    )
    producer = fastkafka._application.app.AIOKafkaProducer()

    await consumer.start()
    await producer.start()

    yield (consumer, producer)

    await consumer.stop()
    await producer.stop()
```

``` python
def checkEqual(L1, L2):
    return len(L1) == len(L2) and sorted(L1) == sorted(L2)
```

``` python
assert checkEqual([1, 2], [3]) == False
assert checkEqual([1, 2, 3], [3, 2, 1]) == True
```

Sanity check, let’s see if the messages are sent to broker and received
by the consumer

``` python
topic = "test_topic"
sent_msgs = [f"msg{i}".encode("UTF-8") for i in range(320)]

with InMemoryBroker() as broker:
    async with create_consumer_and_producer(auto_offset_reset="earliest") as (
        consumer,
        producer,
    ):
        [await producer.send(topic, msg) for msg in sent_msgs]
        consumer.subscribe([topic])
        received = await consumer.getmany()
        received_msgs = [msg.value for _, msgs in received.items() for msg in msgs]
    assert checkEqual(
        received_msgs, sent_msgs
    ), f"{sent_msgs=}\n{received_msgs=}\n{data=}"
```

    [INFO] __main__: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!
    [INFO] __main__: InMemoryBroker starting
    [INFO] __main__: AIOKafkaConsumer patched start() called()
    [INFO] __main__: AIOKafkaProducer patched start() called()
    [INFO] __main__: AIOKafkaConsumer patched subscribe() called
    [INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['test_topic']
    [INFO] __main__: AIOKafkaConsumer patched stop() called
    [INFO] __main__: AIOKafkaProducer patched stop() called
    [INFO] __main__: InMemoryBroker stopping

Check if only subscribed topic messages are received by the consumer

``` python
topic1 = "test_topic1"
topic2 = "test_topic2"
sent_msgs_1 = [(f"msg{i}" + topic1).encode("UTF-8") for i in range(32)]
sent_msgs_2 = [(f"msg{i}" + topic2).encode("UTF-8") for i in range(32)]

with InMemoryBroker() as broker:
    async with create_consumer_and_producer(auto_offset_reset="earliest") as (
        consumer,
        producer,
    ):
        [await producer.send(topic1, msg) for msg in sent_msgs_1]
        [await producer.send(topic2, msg) for msg in sent_msgs_2]

        consumer.subscribe([topic1])
        received = await consumer.getmany()
        received_msgs = [msg.value for _, msgs in received.items() for msg in msgs]

    assert checkEqual(sent_msgs_1, received_msgs)
```

    [INFO] __main__: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!
    [INFO] __main__: InMemoryBroker starting
    [INFO] __main__: AIOKafkaConsumer patched start() called()
    [INFO] __main__: AIOKafkaProducer patched start() called()
    [INFO] __main__: AIOKafkaConsumer patched subscribe() called
    [INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['test_topic1']
    [INFO] __main__: AIOKafkaConsumer patched stop() called
    [INFO] __main__: AIOKafkaProducer patched stop() called
    [INFO] __main__: InMemoryBroker stopping

Check if msgs are received only after subscribing when auto_offset_reset
is set to “latest"

``` python
topic = "test_topic"
sent_msgs_before = [f"msg{i}".encode("UTF-8") for i in range(32)]
sent_msgs_after = [f"msg{i}".encode("UTF-8") for i in range(32, 64)]

with InMemoryBroker() as broker:
    async with create_consumer_and_producer() as (consumer, producer):
        [await producer.send(topic, msg) for msg in sent_msgs_before]

        consumer.subscribe([topic])
        received = await consumer.getmany()
        [await producer.send(topic, msg) for msg in sent_msgs_after]
        received = await consumer.getmany()
        received_msgs = [msg.value for _, msgs in received.items() for msg in msgs]

    assert checkEqual(sent_msgs_after, received_msgs)
```

    [INFO] __main__: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!
    [INFO] __main__: InMemoryBroker starting
    [INFO] __main__: AIOKafkaConsumer patched start() called()
    [INFO] __main__: AIOKafkaProducer patched start() called()
    [INFO] __main__: AIOKafkaConsumer patched subscribe() called
    [INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['test_topic']
    [INFO] __main__: AIOKafkaConsumer patched stop() called
    [INFO] __main__: AIOKafkaProducer patched stop() called
    [INFO] __main__: InMemoryBroker stopping

Check two consumers different groups

``` python
topic = "test_topic"
sent_msgs = [f"msg{i}".encode("UTF-8") for i in range(32)]

with InMemoryBroker() as broker:
    consumer1 = fastkafka._application.app.AIOKafkaConsumer(
        auto_offset_reset="earliest"
    )
    consumer2 = fastkafka._application.app.AIOKafkaConsumer(
        auto_offset_reset="earliest"
    )
    producer = fastkafka._application.app.AIOKafkaProducer()

    await consumer1.start()
    await consumer2.start()
    await producer.start()

    [await producer.send(topic, msg) for msg in sent_msgs]

    consumer1.subscribe([topic])
    received1 = await consumer1.getmany()

    consumer2.subscribe([topic])
    received2 = await consumer2.getmany()

    received_msgs1 = [msg.value for _, msgs in received1.items() for msg in msgs]
    received_msgs2 = [msg.value for _, msgs in received2.items() for msg in msgs]

    await consumer1.stop()
    await consumer2.stop()
    await producer.stop()

    assert checkEqual(sent_msgs, received_msgs1), received_msgs1
    assert checkEqual(sent_msgs, received_msgs2)
```

    [INFO] __main__: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!
    [INFO] __main__: InMemoryBroker starting
    [INFO] __main__: AIOKafkaConsumer patched start() called()
    [INFO] __main__: AIOKafkaConsumer patched start() called()
    [INFO] __main__: AIOKafkaProducer patched start() called()
    [INFO] __main__: AIOKafkaConsumer patched subscribe() called
    [INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['test_topic']
    [INFO] __main__: AIOKafkaConsumer patched subscribe() called
    [INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['test_topic']
    [INFO] __main__: AIOKafkaConsumer patched stop() called
    [INFO] __main__: AIOKafkaConsumer patched stop() called
    [INFO] __main__: AIOKafkaProducer patched stop() called
    [INFO] __main__: InMemoryBroker stopping

Check two consumers same group

``` python
topic = "test_topic"
sent_msgs = [f"msg{i}".encode("UTF-8") for i in range(32)]

with InMemoryBroker(num_partitions=5) as broker:
    consumer1 = fastkafka._application.app.AIOKafkaConsumer(
        group_id="my_group", auto_offset_reset="earliest"
    )
    consumer2 = fastkafka._application.app.AIOKafkaConsumer(
        group_id="my_group", auto_offset_reset="earliest"
    )
    producer = fastkafka._application.app.AIOKafkaProducer()

    await consumer1.start()
    await consumer2.start()
    await producer.start()

    [await producer.send(topic, msg) for msg in sent_msgs]

    consumer1.subscribe([topic])
    consumer2.subscribe([topic])

    received1 = await consumer1.getmany()
    received2 = await consumer2.getmany()

    received_msgs1 = [msg.value for _, msgs in received1.items() for msg in msgs]
    received_msgs2 = [msg.value for _, msgs in received2.items() for msg in msgs]

    await consumer1.stop()
    await consumer2.stop()
    await producer.stop()

    assert checkEqual(sent_msgs, received_msgs1 + received_msgs2)
```

    [INFO] __main__: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!
    [INFO] __main__: InMemoryBroker starting
    [INFO] __main__: AIOKafkaConsumer patched start() called()
    [INFO] __main__: AIOKafkaConsumer patched start() called()
    [INFO] __main__: AIOKafkaProducer patched start() called()
    [INFO] __main__: AIOKafkaConsumer patched subscribe() called
    [INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['test_topic']
    [INFO] __main__: AIOKafkaConsumer patched subscribe() called
    [INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['test_topic']
    [INFO] __main__: AIOKafkaConsumer patched stop() called
    [INFO] __main__: AIOKafkaConsumer patched stop() called
    [INFO] __main__: AIOKafkaProducer patched stop() called
    [INFO] __main__: InMemoryBroker stopping

Check for different bootstrap servers

``` python
topic = "test_topic"
sent_msgs = [f"msg{i}".encode("UTF-8") for i in range(32)]

with InMemoryBroker() as broker:
    for server in ["localhost:9092", "kafka.airt.ai"]:
        consumer = fastkafka._application.app.AIOKafkaConsumer(
            bootstrap_servers=server, auto_offset_reset="earliest"
        )

        producer = fastkafka._application.app.AIOKafkaProducer(bootstrap_servers=server)

        await consumer.start()
        await producer.start()

        [await producer.send(topic, msg) for msg in sent_msgs]

        consumer.subscribe([topic])
        received = await consumer.getmany()

        received_msgs = [msg.value for _, msgs in received.items() for msg in msgs]

        await consumer.stop()
        await producer.stop()

        assert checkEqual(sent_msgs, received_msgs)
```

    [INFO] __main__: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!
    [INFO] __main__: InMemoryBroker starting
    [INFO] __main__: AIOKafkaConsumer patched start() called()
    [INFO] __main__: AIOKafkaProducer patched start() called()
    [INFO] __main__: AIOKafkaConsumer patched subscribe() called
    [INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['test_topic']
    [INFO] __main__: AIOKafkaConsumer patched stop() called
    [INFO] __main__: AIOKafkaProducer patched stop() called
    [INFO] __main__: AIOKafkaConsumer patched start() called()
    [INFO] __main__: AIOKafkaProducer patched start() called()
    [INFO] __main__: AIOKafkaConsumer patched subscribe() called
    [INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['test_topic']
    [INFO] __main__: AIOKafkaConsumer patched stop() called
    [INFO] __main__: AIOKafkaProducer patched stop() called
    [INFO] __main__: InMemoryBroker stopping
