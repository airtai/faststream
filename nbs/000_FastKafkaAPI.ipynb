{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff734a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0745494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import asyncio\n",
    "import functools\n",
    "import json\n",
    "import tempfile\n",
    "import time\n",
    "from asyncio import iscoroutinefunction  # do not use the version from inspect\n",
    "from contextlib import asynccontextmanager, contextmanager\n",
    "from copy import deepcopy\n",
    "from datetime import datetime, timedelta\n",
    "from enum import Enum\n",
    "from inspect import signature\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "from typing import get_type_hints\n",
    "\n",
    "import anyio \n",
    "import asyncer\n",
    "import confluent_kafka\n",
    "import httpx\n",
    "import yaml\n",
    "from aiokafka import AIOKafkaConsumer, AIOKafkaProducer\n",
    "from confluent_kafka import KafkaError, Message, Producer\n",
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "from fastapi import Depends, FastAPI, HTTPException, Request, Response, status\n",
    "from fastapi.openapi.docs import get_redoc_html, get_swagger_ui_html\n",
    "from fastapi.openapi.utils import get_openapi\n",
    "from fastapi.responses import FileResponse, RedirectResponse\n",
    "from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from fastcore.foundation import patch\n",
    "from fastcore.meta import delegates\n",
    "from pydantic import BaseModel, EmailStr, Field, HttpUrl, PositiveInt\n",
    "from pydantic.json import timedelta_isoformat\n",
    "from pydantic.schema import schema\n",
    "\n",
    "import fast_kafka_api._components.logger\n",
    "\n",
    "fast_kafka_api._components.logger.should_supress_timestamps = True\n",
    "\n",
    "import fast_kafka_api\n",
    "from fast_kafka_api._components.aiokafka_consumer_loop import aiokafka_consumer_loop, sanitize_kafka_config\n",
    "from fast_kafka_api._components.aiokafka_producer_manager import AIOKafkaProducerManager\n",
    "from fast_kafka_api._components.asyncapi import (\n",
    "    ConsumeCallable,\n",
    "    ContactInfo,\n",
    "    KafkaBroker,\n",
    "    KafkaBrokers,\n",
    "    KafkaMessage,\n",
    "    KafkaServiceInfo,\n",
    "    ProduceCallable,\n",
    "    export_async_spec,\n",
    ")\n",
    "from fast_kafka_api._components.logger import get_logger, supress_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a28e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf16b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: ok\n"
     ]
    }
   ],
   "source": [
    "supress_timestamps()\n",
    "logger = get_logger(__name__, level=20)\n",
    "logger.info(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdedeee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import unittest.mock\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import nest_asyncio\n",
    "import pytest\n",
    "import uvicorn\n",
    "import yaml\n",
    "from fastapi.testclient import TestClient\n",
    "from rich.pretty import pprint\n",
    "from starlette.datastructures import Headers\n",
    "\n",
    "from fast_kafka_api.testing import mock_AIOKafkaProducer_send, true_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9177ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "# allows async calls in notebooks\n",
    "\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3411e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
    "kafka_server_port = environ[\"KAFKA_PORT\"]\n",
    "\n",
    "kafka_config = {\n",
    "    \"bootstrap_servers\": f\"{kafka_server_url}:{kafka_server_port}\",\n",
    "    \"group_id\": f\"{kafka_server_url}:{kafka_server_port}_group\",\n",
    "    \"auto_offset_reset\": \"earliest\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211534a4",
   "metadata": {},
   "source": [
    "### Constructor utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d213f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@delegates(FastAPI) # type: ignore\n",
    "def _get_fast_api_app(\n",
    "    fast_api_app: Optional[FastAPI] = None,\n",
    "    **kwargs: Dict[str, Any],\n",
    ") -> FastAPI:\n",
    "    if fast_api_app is None:\n",
    "        return FastAPI(\n",
    "            **kwargs # type: ignore\n",
    "        )\n",
    "    else:\n",
    "        return fast_api_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb9eb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_debug=False\n",
      "title=FastAPI\n",
      "description=\n",
      "version=0.1.0\n",
      "terms_of_service=None\n",
      "contact=None\n",
      "license_info=None\n",
      "openapi_url=/openapi.json\n",
      "openapi_tags=None\n",
      "root_path_in_servers=True\n",
      "docs_url=/docs\n",
      "redoc_url=/redoc\n",
      "swagger_ui_oauth2_redirect_url=/docs/oauth2-redirect\n",
      "swagger_ui_init_oauth=None\n",
      "swagger_ui_parameters=None\n",
      "servers=[]\n",
      "extra={}\n",
      "openapi_version=3.0.2\n",
      "openapi_schema=None\n",
      "root_path=\n",
      "state=<starlette.datastructures.State object>\n",
      "dependency_overrides={}\n",
      "router=<fastapi.routing.APIRouter object>\n",
      "exception_handlers={<class 'starlette.exceptions.HTTPException'>: <function http_exception_handler>, <class 'fastapi.exceptions.RequestValidationError'>: <function request_validation_exception_handler>}\n",
      "user_middleware=[]\n",
      "middleware_stack=<starlette.middleware.errors.ServerErrorMiddleware object>\n"
     ]
    }
   ],
   "source": [
    "app = _get_fast_api_app()\n",
    "assert isinstance(app, FastAPI)\n",
    "print(\"\\n\".join([f\"{k}={v}\" for k, v in app.__dict__.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4852ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "def _get_func_with_combined_sig(\n",
    "    fx: List[Callable[[Any], Any]], keep: bool = False\n",
    ") -> Callable[[Any], Any]:\n",
    "    \"\"\"Creates a no-op function with a signature containing parameters from signatures of all functions from `fx`\n",
    "    \n",
    "    Args:\n",
    "        fx: a list of functions\n",
    "        keep: if **True**, keep kwargs as an argument\n",
    "        \n",
    "    Returns:\n",
    "        no-op function with a signature containing parameters from signatures of all functions from `fx`\n",
    "    \"\"\"\n",
    "    def _f(**kwargs):\n",
    "        pass\n",
    "\n",
    "    retval = _f\n",
    "    for f in fx:\n",
    "        retval = delegates(f, keep=True)(retval)\n",
    "    if not keep:\n",
    "        retval = delegates(_f, keep=False)(retval)\n",
    "    return retval # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = _get_func_with_combined_sig([AIOKafkaConsumer.__init__, AIOKafkaProducer.__init__])\n",
    "assert len(signature(f).parameters.keys()) == 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = _get_func_with_combined_sig([AIOKafkaConsumer.__init__, AIOKafkaProducer.__init__], keep=True)\n",
    "assert len(signature(f).parameters.keys()) == 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f978e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@delegates( # type: ignore\n",
    "    _get_func_with_combined_sig([AIOKafkaConsumer.__init__, AIOKafkaProducer.__init__])\n",
    ")\n",
    "def _get_kafka_config(\n",
    "    **kwargs,\n",
    ") -> Dict[str, Any]:\n",
    "    allowed_keys = set(signature(_get_kafka_config).parameters.keys())\n",
    "    if not set(kwargs.keys()) <= allowed_keys:\n",
    "        unallowed_keys = \", \".join(\n",
    "            sorted([f\"'{x}'\" for x in set(kwargs.keys()).difference(allowed_keys)])\n",
    "        )\n",
    "        raise ValueError(f\"Unallowed key arguments passed: {unallowed_keys}\")\n",
    "    retval = kwargs.copy()\n",
    "\n",
    "    # todo: check this values\n",
    "    config_defaults = {\n",
    "        \"bootstrap_servers\": \"localhost:9092\",\n",
    "        \"auto_offset_reset\": \"earliest\",\n",
    "        \"max_poll_records\": 100,\n",
    "        #         \"max_buffer_size\": 10_000,\n",
    "    }\n",
    "    for key, value in config_defaults.items():\n",
    "        if key not in retval:\n",
    "            retval[key] = value\n",
    "\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf9e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _get_kafka_config() == {\n",
    "    \"bootstrap_servers\": \"localhost:9092\",\n",
    "    \"auto_offset_reset\": \"earliest\",\n",
    "    \"max_poll_records\": 100,\n",
    "}\n",
    "\n",
    "assert _get_kafka_config(max_poll_records=1_000) == {\n",
    "    \"bootstrap_servers\": \"localhost:9092\",\n",
    "    \"auto_offset_reset\": \"earliest\",\n",
    "    \"max_poll_records\": 1_000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b17b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pytest.raises(ValueError) as e:\n",
    "    _get_kafka_config(random_key=1_000, whatever=\"whocares\")\n",
    "assert e.value.args == (\"Unallowed key arguments passed: 'random_key', 'whatever'\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3477cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _get_kafka_brokers(\n",
    "    kafka_brokers: Optional[Dict[str, Any]] = None\n",
    ") -> KafkaBrokers:\n",
    "    if kafka_brokers is None:\n",
    "        retval:KafkaBrokers = KafkaBrokers(brokers={\n",
    "            \"localhost\": KafkaBroker(\n",
    "                url=\"https://localhost\",\n",
    "                description=\"Local (dev) Kafka broker\",\n",
    "                port=\"9092\",\n",
    "            )\n",
    "        })\n",
    "    else:\n",
    "        retval = KafkaBrokers(brokers={\n",
    "            k: KafkaBroker.parse_raw(v.json() if hasattr(v, \"json\") else json.dumps(v))\n",
    "            for k, v in kafka_brokers.items()\n",
    "        })\n",
    "        \n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4449bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    _get_kafka_brokers(None).json()\n",
    "    == '{\"brokers\": {\"localhost\": {\"url\": \"https://localhost\", \"description\": \"Local (dev) Kafka broker\", \"protocol\": \"kafka\", \"variables\": {\"port\": {\"default\": \"9092\"}}}}}'\n",
    ")\n",
    "\n",
    "assert (\n",
    "    _get_kafka_brokers(dict(localhost=dict(url=\"localhost\"))).json()\n",
    "    == '{\"brokers\": {\"localhost\": {\"url\": \"localhost\", \"description\": \"Kafka broker\", \"protocol\": \"kafka\", \"variables\": {\"port\": {\"default\": \"9092\"}}}}}'\n",
    ")\n",
    "\n",
    "assert (\n",
    "    _get_kafka_brokers(\n",
    "        dict(localhost=dict(url=\"localhost\"), staging=dict(url=\"staging.airt.ai\"))\n",
    "    ).json()\n",
    "    == '{\"brokers\": {\"localhost\": {\"url\": \"localhost\", \"description\": \"Kafka broker\", \"protocol\": \"kafka\", \"variables\": {\"port\": {\"default\": \"9092\"}}}, \"staging\": {\"url\": \"staging.airt.ai\", \"description\": \"Kafka broker\", \"protocol\": \"kafka\", \"variables\": {\"port\": {\"default\": \"9092\"}}}}}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _get_topic_name(\n",
    "    topic_callable: Union[ConsumeCallable, ProduceCallable], prefix: str = \"on_\"\n",
    ") -> str:\n",
    "    topic = topic_callable.__name__\n",
    "    if not topic.startswith(prefix) or len(topic) <= len(prefix):\n",
    "        raise ValueError(f\"Function name '{topic}' must start with {prefix}\")\n",
    "    topic = topic[len(prefix) :]\n",
    "\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_topic_name_1():\n",
    "    pass\n",
    "\n",
    "\n",
    "assert _get_topic_name(on_topic_name_1) == \"topic_name_1\"\n",
    "\n",
    "assert _get_topic_name(on_topic_name_1, prefix=\"on_topic_\") == \"name_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e9f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def _get_contact_info(\n",
    "    name: str=\"Author\", url: str=\"https://www.google.com\", email:str=\"noreply@gmail.com\"\n",
    ") -> ContactInfo:\n",
    "    return ContactInfo(name=name, url=url, email=email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e311f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContactInfo(name='Author', url=HttpUrl('https://www.google.com', ), email='noreply@gmail.com')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_contact_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c37353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class FastKafkaAPI:\n",
    "    @delegates(  # type: ignore\n",
    "        _get_func_with_combined_sig(\n",
    "            [AIOKafkaConsumer.__init__, AIOKafkaProducer.__init__]\n",
    "        )\n",
    "    )\n",
    "    def __init__(\n",
    "        self,\n",
    "        fast_api_app: FastAPI,\n",
    "        *,\n",
    "        asyncapi_route: Optional[str] = \"/asyncapi\",\n",
    "        title: Optional[str] = None,\n",
    "        description: Optional[str] = None,\n",
    "        version: Optional[str] = None,\n",
    "        contact: Optional[Dict[str, str]] = None,\n",
    "        kafka_brokers: Optional[Dict[str, Any]] = None,\n",
    "        root_path: Optional[Union[Path, str]] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Combined REST and Kafka service\n",
    "\n",
    "        Params:\n",
    "            fast_api_app: the FastAPI app, if None, one will be created\n",
    "            asyncapi_route: the route to where to mount the documentation. If **None**, the docs will not be mounted.\n",
    "            title: optional title for the documentation. If None, the title of passed fast_api_app will be used\n",
    "            description: optional description for the documentation. If None, the description of passed fast_api_app will be used\n",
    "            version: optional version for the documentation. If None, the version of passed fast_api_app will be used\n",
    "            contact: optional contact for the documentation. If None, the contact of passed fast_api_app will be used\n",
    "            kafka_brokers: dictionary describing kafka brokers used for generating documentation\n",
    "            root_path: path to where documentation will be created\n",
    "        \"\"\"\n",
    "        self._fast_api_app = fast_api_app\n",
    "\n",
    "        # this is neede for documentation generation\n",
    "        self._title = title if title else fast_api_app.title\n",
    "        self._description = description if description else fast_api_app.description\n",
    "        self._version = version if version else fast_api_app.version\n",
    "        if contact is not None:\n",
    "            self._contact_info = _get_contact_info(**contact)\n",
    "        elif fast_api_app.contact is not None:\n",
    "            if isinstance(fast_api_app.contact, str):\n",
    "                self._contact_info = _get_contact_info(name=fast_api_app.contact)\n",
    "            else:\n",
    "                self._contact_info = _get_contact_info(**fast_api_app.contact)\n",
    "        else:\n",
    "            self._contact_info = _get_contact_info()\n",
    "\n",
    "        self._kafka_service_info = KafkaServiceInfo(\n",
    "            title=self._title,\n",
    "            version=self._version,\n",
    "            description=self._description,\n",
    "            contact=self._contact_info,\n",
    "        )\n",
    "        self._kafka_brokers = _get_kafka_brokers(kafka_brokers)\n",
    "\n",
    "        self._root_path = Path(\".\") if root_path is None else Path(root_path)\n",
    "\n",
    "        # this is used as default parameters for creating AIOProducer and AIOConsumer objects\n",
    "        self._kafka_config = _get_kafka_config(**kwargs)\n",
    "\n",
    "        #\n",
    "        self._consumers_store: Dict[str, Tuple[ConsumeCallable, Dict[str, Any]]] = {}\n",
    "\n",
    "        self._producers_list: List[  # type: ignore\n",
    "            Union[AIOKafkaProducer, AIOKafkaProducerManager]\n",
    "        ] = []\n",
    "        self._producers_store: Dict[  # type: ignore\n",
    "            str, Tuple[ProduceCallable, AIOKafkaProducer, Dict[str, Any]]\n",
    "        ] = {}\n",
    "\n",
    "        # background tasks\n",
    "        self._scheduled_bg_tasks: List[Callable[..., Coroutine[Any, Any, Any]]] = []\n",
    "        self._bg_task_group_generator: Optional[anyio.abc.TaskGroup] = None\n",
    "        self._bg_tasks_group: Optional[anyio.abc.TaskGroup]\n",
    "\n",
    "        # todo: use this for errrors\n",
    "        self._on_error_topic: Optional[str] = None\n",
    "\n",
    "        self._asyncapi_path = self._root_path / \"asyncapi\"\n",
    "        (self._asyncapi_path / \"docs\").mkdir(exist_ok=True, parents=True)\n",
    "        (self._asyncapi_path / \"spec\").mkdir(exist_ok=True, parents=True)\n",
    "        self._fast_api_app.mount(\n",
    "            \"/asyncapi\",\n",
    "            StaticFiles(directory=self._asyncapi_path / \"docs\"),\n",
    "            name=\"asyncapi\",\n",
    "        )\n",
    "\n",
    "        self._is_shutting_down: bool = False\n",
    "        self._kafka_consumer_tasks: List[asyncio.Task[Any]] = []\n",
    "        self._kafka_producer_tasks: List[asyncio.Task[Any]] = []\n",
    "\n",
    "        @self._fast_api_app.get(\"/\", include_in_schema=False)\n",
    "        def redirect_root_to_asyncapi():\n",
    "            return RedirectResponse(\"/asyncapi\")\n",
    "\n",
    "        @self._fast_api_app.get(\"/asyncapi\", include_in_schema=False)\n",
    "        async def redirect_asyncapi_docs():\n",
    "            return RedirectResponse(\"/asyncapi/index.html\")\n",
    "\n",
    "        @self._fast_api_app.get(\"/asyncapi.yml\", include_in_schema=False)\n",
    "        async def download_asyncapi_yml():\n",
    "            return FileResponse(self._asyncapi_path / \"spec\" / \"asyncapi.yml\")\n",
    "\n",
    "        @self._fast_api_app.on_event(\"startup\")\n",
    "        async def on_startup(app=self):\n",
    "            await app._on_startup()\n",
    "\n",
    "        @self._fast_api_app.on_event(\"shutdown\")\n",
    "        async def on_shutdown(app=self):\n",
    "            await app._on_shutdown()\n",
    "\n",
    "    async def _on_startup(self) -> None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    async def _on_shutdown(self) -> None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def consumes(\n",
    "        self,\n",
    "        topic: Optional[str] = None,\n",
    "        *,\n",
    "        prefix: str = \"on_\",\n",
    "        **kwargs: Dict[str, Any],\n",
    "    ) -> ConsumeCallable:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def produces(  # type: ignore\n",
    "        self,\n",
    "        topic: Optional[str] = None,\n",
    "        *,\n",
    "        prefix: str = \"to_\",\n",
    "        producer: Optional[AIOKafkaProducer] = None,\n",
    "        **kwargs: Dict[str, Any],\n",
    "    ) -> ProduceCallable:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def run_in_background(\n",
    "        self,\n",
    "    ) -> Callable[[], Any]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _populate_consumers(\n",
    "        self,\n",
    "        is_shutting_down_f: Callable[[], bool],\n",
    "    ) -> None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    async def _populate_producers(self) -> None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def generate_async_spec(self) -> None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    async def _shutdown_consumers(self) -> None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    async def _shutdown_producers(self) -> None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    async def _populate_bg_tasks(self) -> None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    async def _shutdown_bg_tasks(self) -> None:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894af799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_fast_api_app': <fastapi.applications.FastAPI>,\n",
       " '_title': 'FastAPI',\n",
       " '_description': '',\n",
       " '_version': '0.1.0',\n",
       " '_contact_info': ContactInfo(name='Author', url=HttpUrl('https://www.google.com', ), email='noreply@gmail.com'),\n",
       " '_kafka_service_info': KafkaServiceInfo(title='FastAPI', version='0.1.0', description='', contact=ContactInfo(name='Author', url=HttpUrl('https://www.google.com', ), email='noreply@gmail.com')),\n",
       " '_kafka_brokers': KafkaBrokers(brokers={'localhost': KafkaBroker(url='https://localhost', description='Local (dev) Kafka broker', port='9092', protocol='kafka', security=None)}),\n",
       " '_root_path': PosixPath('.'),\n",
       " '_kafka_config': {'bootstrap_servers': 'localhost:9092',\n",
       "  'auto_offset_reset': 'earliest',\n",
       "  'max_poll_records': 100},\n",
       " '_consumers_store': {},\n",
       " '_producers_list': [],\n",
       " '_producers_store': {},\n",
       " '_scheduled_bg_tasks': [],\n",
       " '_bg_task_group_generator': None,\n",
       " '_on_error_topic': None,\n",
       " '_asyncapi_path': PosixPath('asyncapi'),\n",
       " '_is_shutting_down': False,\n",
       " '_kafka_consumer_tasks': [],\n",
       " '_kafka_producer_tasks': []}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = FastAPI()\n",
    "kafka_app = FastKafkaAPI(app)\n",
    "kafka_app.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b99de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_fast_api_app': <fastapi.applications.FastAPI>,\n",
       " '_title': 'FastAPI',\n",
       " '_description': '',\n",
       " '_version': '0.1.0',\n",
       " '_contact_info': ContactInfo(name='Davor', url=HttpUrl('https://www.google.com', ), email='noreply@gmail.com'),\n",
       " '_kafka_service_info': KafkaServiceInfo(title='FastAPI', version='0.1.0', description='', contact=ContactInfo(name='Davor', url=HttpUrl('https://www.google.com', ), email='noreply@gmail.com')),\n",
       " '_kafka_brokers': KafkaBrokers(brokers={'localhost': KafkaBroker(url='https://localhost', description='Local (dev) Kafka broker', port='9092', protocol='kafka', security=None)}),\n",
       " '_root_path': PosixPath('.'),\n",
       " '_kafka_config': {'bootstrap_servers': 'localhost:9092',\n",
       "  'auto_offset_reset': 'earliest',\n",
       "  'max_poll_records': 100},\n",
       " '_consumers_store': {},\n",
       " '_producers_list': [],\n",
       " '_producers_store': {},\n",
       " '_scheduled_bg_tasks': [],\n",
       " '_bg_task_group_generator': None,\n",
       " '_on_error_topic': None,\n",
       " '_asyncapi_path': PosixPath('asyncapi'),\n",
       " '_is_shutting_down': False,\n",
       " '_kafka_consumer_tasks': [],\n",
       " '_kafka_producer_tasks': []}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = FastAPI(contact=\"Davor\")\n",
    "kafka_app = FastKafkaAPI(app)\n",
    "kafka_app.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfbe17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_testing_app():\n",
    "    root_path = \"/tmp/000_FastKafkaAPI\"\n",
    "    if Path(root_path).exists():\n",
    "        shutil.rmtree(root_path)\n",
    "\n",
    "    app = FastAPI()\n",
    "    kafka_app = FastKafkaAPI(\n",
    "        app,\n",
    "        kafka_brokers={\n",
    "            \"local\": {\n",
    "                \"url\": \"kafka\",\n",
    "                \"name\": \"development\",\n",
    "                \"description\": \"Local (dev) Kafka broker\",\n",
    "                \"port\": 9092,\n",
    "            }\n",
    "        },\n",
    "        root_path=root_path,\n",
    "        **kafka_config,\n",
    "    )\n",
    "\n",
    "    return kafka_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66237424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.FastKafkaAPI>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = create_testing_app()\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cddd5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch  # type: ignore\n",
    "def consumes(\n",
    "    self: FastKafkaAPI,\n",
    "    topic: Optional[str] = None,\n",
    "    *,\n",
    "    prefix: str = \"on_\",\n",
    "    **kwargs: Dict[str, Any],\n",
    ") -> Callable[[ConsumeCallable], ConsumeCallable]:\n",
    "    \"\"\"Decorator registering the callback called when a message is received in a topic.\n",
    "\n",
    "    This function decorator is also responsible for registering topics for AsyncAPI specificiation and documentation.\n",
    "\n",
    "    Params:\n",
    "        topic: Kafka topic that the consumer will subscribe to and execute the decorated function when it receives a message from the topic, default: None\n",
    "            If the topic is not specified, topic name will be inferred from the decorated function name by stripping the defined prefix\n",
    "        prefix: Prefix stripped from the decorated function to define a topic name if the topic argument is not passed, default: \"on_\"\n",
    "            If the decorated function name is not prefixed with the defined prefix and topic argument is not passed, then this method will throw ValueError\n",
    "        **kwargs: Keyword arguments that will be passed to AIOKafkaConsumer, used to configure the consumer\n",
    "\n",
    "    Returns:\n",
    "        A function returning the same function\n",
    "\n",
    "    Throws:\n",
    "        ValueError\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def _decorator(\n",
    "        on_topic: ConsumeCallable,\n",
    "        topic: Optional[str] = topic,\n",
    "        kwargs: Dict[str, Any] = kwargs,\n",
    "    ) -> ConsumeCallable:\n",
    "        topic_resolved: str = (\n",
    "            _get_topic_name(topic_callable=on_topic, prefix=prefix)\n",
    "            if topic is None\n",
    "            else topic\n",
    "        )\n",
    "\n",
    "        self._consumers_store[topic_resolved] = (on_topic, kwargs)\n",
    "\n",
    "        return on_topic\n",
    "\n",
    "    return _decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb7fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = create_testing_app()\n",
    "\n",
    "# Basic check\n",
    "@app.consumes()\n",
    "def on_my_topic_1(msg: BaseModel) -> None:\n",
    "    pass\n",
    "\n",
    "\n",
    "assert app._consumers_store[\"my_topic_1\"] == (on_my_topic_1, {}), app._consumers_store\n",
    "\n",
    "# Check topic setting\n",
    "@app.consumes(topic=\"test_topic_2\")\n",
    "def some_func_name(msg: BaseModel) -> None:\n",
    "    pass\n",
    "\n",
    "\n",
    "assert app._consumers_store[\"test_topic_2\"] == (\n",
    "    some_func_name,\n",
    "    {},\n",
    "), app._consumers_store\n",
    "\n",
    "# Check prefix change\n",
    "@app.consumes(prefix=\"for_\")\n",
    "def for_test_topic_3(msg: BaseModel) -> None:\n",
    "    pass\n",
    "\n",
    "\n",
    "assert app._consumers_store[\"test_topic_3\"] == (\n",
    "    for_test_topic_3,\n",
    "    {},\n",
    "), app._consumers_store\n",
    "\n",
    "# Check passing of kwargs\n",
    "kwargs = {\"arg1\": \"val1\", \"arg2\": 2}\n",
    "\n",
    "\n",
    "@app.consumes(topic=\"test_topic\", **kwargs)\n",
    "def for_test_kwargs(msg: BaseModel):\n",
    "    pass\n",
    "\n",
    "\n",
    "assert app._consumers_store[\"test_topic\"] == (\n",
    "    for_test_kwargs,\n",
    "    kwargs,\n",
    "), app._consumers_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002589f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _to_json_utf8(o: Any) -> bytes:\n",
    "    \"\"\"Converts to JSON and then encodes with UTF-8\"\"\"\n",
    "    if hasattr(o, \"json\"):\n",
    "        return o.json().encode(\"utf-8\")  # type: ignore\n",
    "    else:\n",
    "        return json.dumps(o).encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f9ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _to_json_utf8({\"a\": 1, \"b\": [2, 3]}) == b'{\"a\": 1, \"b\": [2, 3]}'\n",
    "\n",
    "\n",
    "class A(BaseModel):\n",
    "    name: str = Field()\n",
    "    age: int\n",
    "\n",
    "\n",
    "assert _to_json_utf8(A(name=\"Davor\", age=12)) == b'{\"name\": \"Davor\", \"age\": 12}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e6fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def produce_decorator(\n",
    "    self: FastKafkaAPI, func: ProduceCallable, topic: str\n",
    ") -> ProduceCallable:\n",
    "    @functools.wraps(func)\n",
    "    async def _produce_async(*args: List[Any], **kwargs: Dict[str, Any]) -> BaseModel:\n",
    "        f: Callable[..., Awaitable[BaseModel]] = func  # type: ignore\n",
    "        return_val = await f(*args, **kwargs)\n",
    "        _, producer, _ = self._producers_store[topic]\n",
    "        fut = await producer.send(topic, _to_json_utf8(return_val))\n",
    "        msg = await fut\n",
    "        return return_val\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def _produce_sync(*args: List[Any], **kwargs: Dict[str, Any]) -> BaseModel:\n",
    "        f: Callable[..., BaseModel] = func  # type: ignore\n",
    "        return_val = f(*args, **kwargs)\n",
    "        _, producer, _ = self._producers_store[topic]\n",
    "        producer.send(topic, _to_json_utf8(return_val))\n",
    "        return return_val\n",
    "\n",
    "    return _produce_async if iscoroutinefunction(func) else _produce_sync  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de8051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Entering...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting task group\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting send_stream\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Entering...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting send_stream\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting task group\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Stoping producer...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Finished\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "async def test_me(is_async: bool):\n",
    "    with mock_AIOKafkaProducer_send() as send_mock:\n",
    "        topic = \"test_topic\"\n",
    "\n",
    "        class MockMsg(BaseModel):\n",
    "            name: str = \"Micky Mouse\"\n",
    "            id: int = 123\n",
    "\n",
    "        if is_async:\n",
    "\n",
    "            async def func(mock_msg: MockMsg) -> MockMsg:\n",
    "                return mock_msg\n",
    "\n",
    "        else:\n",
    "\n",
    "            def func(mock_msg: MockMsg) -> MockMsg:\n",
    "                return mock_msg\n",
    "\n",
    "        producer = AIOKafkaProducer(bootstrap_servers=kafka_config[\"bootstrap_servers\"])\n",
    "        if not is_async:\n",
    "            producer = AIOKafkaProducerManager(producer)\n",
    "\n",
    "        await producer.start()\n",
    "        try:\n",
    "            app = unittest.mock.Mock()\n",
    "            app._producers_store = {topic: (func, producer, {})}\n",
    "\n",
    "            test_func = produce_decorator(app, func, topic)\n",
    "            assert iscoroutinefunction(test_func) == is_async\n",
    "\n",
    "            mock_msg = MockMsg()\n",
    "            if not is_async:\n",
    "                value = test_func(mock_msg)\n",
    "                await asyncio.sleep(1)\n",
    "            else:\n",
    "                value = await test_func(mock_msg)\n",
    "\n",
    "            send_mock.assert_called_once_with(topic, mock_msg.json().encode(\"utf-8\"))\n",
    "            assert value == mock_msg\n",
    "\n",
    "        finally:\n",
    "            await producer.stop()\n",
    "\n",
    "\n",
    "for is_async in [True, False]:\n",
    "    await test_me(is_async)\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e269659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch  # type: ignore\n",
    "def produces(\n",
    "    self: FastKafkaAPI,\n",
    "    topic: Optional[str] = None,\n",
    "    *,\n",
    "    prefix: str = \"to_\",\n",
    "    producer: AIOKafkaProducer = None,\n",
    "    **kwargs: Dict[str, Any],\n",
    ") -> Callable[[ProduceCallable], ProduceCallable]:\n",
    "    \"\"\"Decorator registering the callback called when delivery report for a produced message is received\n",
    "\n",
    "    This function decorator is also responsible for registering topics for AsyncAPI specificiation and documentation.\n",
    "\n",
    "    Params:\n",
    "        topic: Kafka topic that the producer will send returned values from the decorated function to, default: None\n",
    "            If the topic is not specified, topic name will be inferred from the decorated function name by stripping the defined prefix\n",
    "        prefix: Prefix stripped from the decorated function to define a topic name if the topic argument is not passed, default: \"to_\"\n",
    "            If the decorated function name is not prefixed with the defined prefix and topic argument is not passed, then this method will throw ValueError\n",
    "        producer:\n",
    "        **kwargs: Keyword arguments that will be passed to AIOKafkaProducer, used to configure the producer\n",
    "\n",
    "    Returns:\n",
    "        A function returning the same function\n",
    "\n",
    "    Throws:\n",
    "        ValueError\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def _decorator(\n",
    "        on_topic: ProduceCallable,\n",
    "        topic: Optional[str] = topic,\n",
    "        kwargs: Dict[str, Any] = kwargs,\n",
    "    ) -> ProduceCallable:\n",
    "        topic_resolved: str = (\n",
    "            _get_topic_name(topic_callable=on_topic, prefix=prefix)\n",
    "            if topic is None\n",
    "            else topic\n",
    "        )\n",
    "\n",
    "        self._producers_store[topic_resolved] = (on_topic, producer, kwargs)\n",
    "\n",
    "        return produce_decorator(self, on_topic, topic_resolved)\n",
    "\n",
    "    return _decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf7cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = create_testing_app()\n",
    "\n",
    "# Basic check\n",
    "async def to_my_topic_1(msg: BaseModel) -> None:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Must be done without sugar to keep the original function reference\n",
    "check_func = to_my_topic_1\n",
    "to_my_topic_1 = app.produces()(to_my_topic_1)\n",
    "\n",
    "assert app._producers_store[\"my_topic_1\"] == (\n",
    "    check_func,\n",
    "    None,\n",
    "    {},\n",
    "), f\"{app._producers_store}, {to_my_topic_1}\"\n",
    "\n",
    "# Check topic setting\n",
    "def some_func_name(msg: BaseModel) -> None:\n",
    "    pass\n",
    "\n",
    "\n",
    "check_func = some_func_name\n",
    "some_func_name = app.produces(topic=\"test_topic_2\")(some_func_name)\n",
    "\n",
    "assert app._producers_store[\"test_topic_2\"] == (\n",
    "    check_func,\n",
    "    None,\n",
    "    {},\n",
    "), app._producers_store\n",
    "\n",
    "# Check prefix change\n",
    "@app.produces(prefix=\"for_\")\n",
    "def for_test_topic_3(msg: BaseModel) -> None:\n",
    "    pass\n",
    "\n",
    "\n",
    "check_func = for_test_topic_3\n",
    "some_func_name = app.produces(prefix=\"for_\")(for_test_topic_3)\n",
    "\n",
    "assert app._producers_store[\"test_topic_3\"] == (\n",
    "    check_func,\n",
    "    None,\n",
    "    {},\n",
    "), app._producers_store\n",
    "\n",
    "# Check passing of kwargs\n",
    "kwargs = {\"arg1\": \"val1\", \"arg2\": 2}\n",
    "\n",
    "\n",
    "async def for_test_kwargs(msg: BaseModel):\n",
    "    pass\n",
    "\n",
    "\n",
    "check_func = for_test_kwargs\n",
    "for_test_kwargs = app.produces(topic=\"test_topic\", **kwargs)(for_test_kwargs)\n",
    "\n",
    "assert app._producers_store[\"test_topic\"] == (\n",
    "    check_func,\n",
    "    None,\n",
    "    kwargs,\n",
    "), app._producers_store\n",
    "\n",
    "# Check passing of custom Producer\n",
    "async def test_me():\n",
    "    kwargs = {\"arg1\": \"val1\", \"arg2\": 2}\n",
    "\n",
    "    async def for_test_producer(msg: BaseModel):\n",
    "        pass\n",
    "\n",
    "    check_func = for_test_producer\n",
    "    producer = AIOKafkaProducer()\n",
    "    for_test_producer = app.produces(\n",
    "        topic=\"test_producer\", producer=producer, **kwargs\n",
    "    )(for_test_producer)\n",
    "\n",
    "    assert app._producers_store[\"test_producer\"] == (\n",
    "        check_func,\n",
    "        producer,\n",
    "        kwargs,\n",
    "    ), app._producers_store\n",
    "\n",
    "\n",
    "await test_me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4744bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch # type: ignore\n",
    "def run_in_background(\n",
    "    self: FastKafkaAPI,\n",
    ") -> Callable[[Callable[..., Coroutine[Any, Any, Any]]], Callable[..., Coroutine[Any, Any, Any]]]:\n",
    "    \"\"\"\n",
    "    Decorator to schedule a task to be run in the background.\n",
    "\n",
    "    This decorator is used to schedule a task to be run in the background when the app's `_on_startup` event is triggered.\n",
    "\n",
    "    Returns:\n",
    "        Callable[None, None]: A decorator function that takes a background task as an input and stores it to be run in the backround.\n",
    "    \"\"\"\n",
    "    \n",
    "    def _decorator(bg_task: Callable[..., Coroutine[Any, Any, Any]]) -> Callable[..., Coroutine[Any, Any, Any]]:\n",
    "        \"\"\"\n",
    "        Store the background task.\n",
    "\n",
    "        Args:\n",
    "            bg_task (Callable[[], None]): The background task to be run asynchronously.\n",
    "\n",
    "        Returns:\n",
    "            Callable[[], None]: Original background task.\n",
    "        \"\"\"\n",
    "        self._scheduled_bg_tasks.append(bg_task)\n",
    "        \n",
    "        return bg_task\n",
    "\n",
    "    return _decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16917ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the background job is getting registered\n",
    "\n",
    "app = create_testing_app()\n",
    "\n",
    "@app.run_in_background()\n",
    "async def async_background_job():\n",
    "    pass\n",
    "\n",
    "assert app._scheduled_bg_tasks[0] == async_background_job, app._scheduled_bg_tasks[0]\n",
    "assert app._scheduled_bg_tasks.__len__() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e107bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyInfo(BaseModel):\n",
    "    mobile: str = Field(..., example=\"+385987654321\")\n",
    "    name: str = Field(..., example=\"James Bond\")\n",
    "\n",
    "\n",
    "class MyMsgUrl(BaseModel):\n",
    "    info: MyInfo = Field(..., example=dict(mobile=\"+385987654321\", name=\"James Bond\"))\n",
    "    url: HttpUrl = Field(..., example=\"https://sis.gov.uk/agents/007\")\n",
    "\n",
    "\n",
    "class MyMsgEmail(BaseModel):\n",
    "    msg_url: MyMsgUrl = Field(\n",
    "        ...,\n",
    "        example=dict(\n",
    "            info=dict(mobile=\"+385987654321\", name=\"James Bond\"),\n",
    "            url=\"https://sis.gov.uk/agents/007\",\n",
    "        ),\n",
    "    )\n",
    "    email: EmailStr = Field(..., example=\"agent-007@sis.gov.uk\")\n",
    "\n",
    "\n",
    "def setup_testing_app():\n",
    "    app = create_testing_app()\n",
    "\n",
    "    @app.consumes(\"my_topic_1\")\n",
    "    def on_my_topic_one(msg: MyMsgUrl) -> None:\n",
    "        logger.debug(f\"on_my_topic_one(msg={msg},)\")\n",
    "\n",
    "    @app.consumes()\n",
    "    async def on_my_topic_2(msg: MyMsgEmail) -> None:\n",
    "        logger.debug(f\"on_my_topic_2(msg={msg},)\")\n",
    "\n",
    "    with pytest.raises(ValueError) as e:\n",
    "\n",
    "        @app.consumes()\n",
    "        def my_topic_3(msg: MyMsgEmail) -> None:\n",
    "            raise NotImplemented\n",
    "\n",
    "    @app.produces()\n",
    "    def to_my_topic_3(url: str) -> MyMsgUrl:\n",
    "        logger.debug(f\"on_my_topic_3(msg={url}\")\n",
    "        return MyMsgUrl(info=MyInfo(\"+3851987654321\", \"Sean Connery\"), url=url)\n",
    "\n",
    "    @app.produces()\n",
    "    async def to_my_topic_4(msg: MyMsgEmail) -> MyMsgEmail:\n",
    "        logger.debug(f\"on_my_topic_4(msg={msg}\")\n",
    "        return msg\n",
    "\n",
    "    @app.produces()\n",
    "    def to_my_topic_5(url: str) -> MyMsgUrl:\n",
    "        logger.debug(f\"on_my_topic_5(msg={url}\")\n",
    "        return MyMsgUrl(info=MyInfo(\"+3859123456789\", \"John Wayne\"), url=url)\n",
    "    \n",
    "    @app.run_in_background()\n",
    "    async def long_bg_job():\n",
    "        await asyncio.sleep(100) \n",
    "\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a945425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app._kafka_service_info=title='FastAPI' version='0.1.0' description='' contact=ContactInfo(name='Author', url=HttpUrl('https://www.google.com', ), email='noreply@gmail.com')\n",
      "app._kafka_brokers=brokers={'local': KafkaBroker(url='kafka', description='Local (dev) Kafka broker', port='9092', protocol='kafka', security=None)}\n"
     ]
    }
   ],
   "source": [
    "app = setup_testing_app()\n",
    "\n",
    "assert set(app._consumers_store.keys()) == set([\"my_topic_1\", \"my_topic_2\"])\n",
    "assert set(app._producers_store.keys()) == set(\n",
    "    [\"my_topic_3\", \"my_topic_4\", \"my_topic_5\"]\n",
    ")\n",
    "\n",
    "print(f\"app._kafka_service_info={app._kafka_service_info}\")\n",
    "print(f\"app._kafka_brokers={app._kafka_brokers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e338a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def filter_using_signature(f: Callable, **kwargs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    param_names = list(signature(f).parameters.keys())\n",
    "    return {k: v for k, v in kwargs.items() if k in param_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a: int, *, b: str):\n",
    "    pass\n",
    "\n",
    "\n",
    "assert filter_using_signature(f, a=1, c=3) == {\"a\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ea338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch  # type: ignore\n",
    "def _populate_consumers(\n",
    "    self: FastKafkaAPI,\n",
    "    is_shutting_down_f: Callable[[], bool],\n",
    ") -> None:\n",
    "    default_config: Dict[str, Any] = filter_using_signature(\n",
    "        AIOKafkaConsumer, **self._kafka_config\n",
    "    )\n",
    "    self._kafka_consumer_tasks = [\n",
    "        asyncio.create_task(\n",
    "            aiokafka_consumer_loop(\n",
    "                topics=[topic],\n",
    "                callbacks={topic: consumer},\n",
    "                msg_types={topic: signature(consumer).parameters[\"msg\"].annotation},\n",
    "                is_shutting_down_f=is_shutting_down_f,\n",
    "                **{**default_config, **override_config},\n",
    "            )\n",
    "        )\n",
    "        for topic, (consumer, override_config) in self._consumers_store.items()\n",
    "    ]\n",
    "\n",
    "\n",
    "@patch  # type: ignore\n",
    "async def _shutdown_consumers(\n",
    "    self: FastKafkaAPI,\n",
    ") -> None:\n",
    "    if self._kafka_consumer_tasks:\n",
    "        await asyncio.wait(self._kafka_consumer_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df10b5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'tvrtko-fast-kafka-api-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'tvrtko-fast-kafka-api-kafka-1:9092_group'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'tvrtko-fast-kafka-api-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'tvrtko-fast-kafka-api-kafka-1:9092_group'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'my_topic_2'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'my_topic_2'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'my_topic_1'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'my_topic_1'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1003 for group tvrtko-fast-kafka-api-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group tvrtko-fast-kafka-api-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group tvrtko-fast-kafka-api-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'tvrtko-fast-kafka-api-kafka-1:9092_group' (generation 22) with member_id aiokafka-0.8.0-3d964faa-a6d1-427d-9eb9-306d6961474d\n",
      "[INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1003 for group tvrtko-fast-kafka-api-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group tvrtko-fast-kafka-api-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group tvrtko-fast-kafka-api-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group tvrtko-fast-kafka-api-kafka-1:9092_group with generation 22\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='my_topic_2', partition=0)} for group tvrtko-fast-kafka-api-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'tvrtko-fast-kafka-api-kafka-1:9092_group' (generation 23) with member_id aiokafka-0.8.0-664afe67-8fa3-4eef-937e-f5a59a9f0164\n",
      "[INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group tvrtko-fast-kafka-api-kafka-1:9092_group with generation 23\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='my_topic_1', partition=0)} for group tvrtko-fast-kafka-api-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n"
     ]
    }
   ],
   "source": [
    "app = setup_testing_app()\n",
    "app._populate_consumers(is_shutting_down_f=true_after(1))\n",
    "assert len(app._kafka_consumer_tasks) == 2\n",
    "\n",
    "await app._shutdown_consumers()\n",
    "\n",
    "assert all([t.done() for t in app._kafka_consumer_tasks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6ee2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "# TODO: Add passing of vars\n",
    "async def _create_producer(  # type: ignore\n",
    "    *,\n",
    "    callback: ProduceCallable,\n",
    "    producer: Optional[AIOKafkaProducer],\n",
    "    default_config: Dict[str, Any],\n",
    "    override_config: Dict[str, Any],\n",
    "    producers_list: List[Union[AIOKafkaProducer, AIOKafkaProducerManager]],\n",
    ") -> Union[AIOKafkaProducer, AIOKafkaProducerManager]:\n",
    "    \"\"\"Creates a producer\n",
    "\n",
    "    Args:\n",
    "        callback: A callback function that is called when the producer is ready.\n",
    "        producer: An existing producer to use.\n",
    "        default_config: A dictionary of default configuration values.\n",
    "        override_config: A dictionary of configuration values to override.\n",
    "        producers_list: A list of producers to add the new producer to.\n",
    "\n",
    "    Returns:\n",
    "        A producer.\n",
    "    \"\"\"\n",
    "\n",
    "    if producer is None:\n",
    "        config = {\n",
    "            **filter_using_signature(AIOKafkaProducer, **default_config),\n",
    "            **override_config,\n",
    "        }\n",
    "        producer = AIOKafkaProducer(**config)\n",
    "        logger.info(f\"_create_producer() : created producer using the config: '{sanitize_kafka_config(**config)}'\")\n",
    "\n",
    "    if not iscoroutinefunction(callback):\n",
    "        producer = AIOKafkaProducerManager(producer)\n",
    "\n",
    "    await producer.start()\n",
    "\n",
    "    producers_list.append(producer)\n",
    "\n",
    "    return producer\n",
    "\n",
    "\n",
    "@patch  # type: ignore\n",
    "async def _populate_producers(self: FastKafkaAPI) -> None:\n",
    "    \"\"\"Populates the producers for the FastKafkaAPI instance.\n",
    "\n",
    "    Args:\n",
    "        self: The FastKafkaAPI instance.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "\n",
    "    Raises:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    default_config: Dict[str, Any] = self._kafka_config\n",
    "    self._producers_list = []\n",
    "    self._producers_store = {\n",
    "        topic: (\n",
    "            callback,\n",
    "            await _create_producer(\n",
    "                callback=callback,\n",
    "                producer=producer,\n",
    "                default_config=default_config,\n",
    "                override_config=override_config,\n",
    "                producers_list=self._producers_list,\n",
    "            ),\n",
    "            override_config,\n",
    "        )\n",
    "        for topic, (\n",
    "            callback,\n",
    "            producer,\n",
    "            override_config,\n",
    "        ) in self._producers_store.items()\n",
    "    }\n",
    "\n",
    "\n",
    "@patch  # type: ignore\n",
    "async def _shutdown_producers(self: FastKafkaAPI) -> None:\n",
    "    [await producer.stop() for producer in self._producers_list[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546037d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fast-kafka-api-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Entering...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting task group\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting send_stream\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Finished.\n",
      "[INFO] __main__: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fast-kafka-api-kafka-1:9092'}'\n",
      "[INFO] __main__: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fast-kafka-api-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Entering...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting task group\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting send_stream\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Entering...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting send_stream\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting task group\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Stoping producer...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Finished\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Entering...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting send_stream\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting task group\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Stoping producer...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<fast_kafka_api._components.aiokafka_producer_manager.AIOKafkaProducerManager>,\n",
       " <aiokafka.producer.producer.AIOKafkaProducer>,\n",
       " <fast_kafka_api._components.aiokafka_producer_manager.AIOKafkaProducerManager>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = setup_testing_app()\n",
    "await app._populate_producers()\n",
    "await app._shutdown_producers()\n",
    "assert len(app._producers_list) == 3\n",
    "\n",
    "app._producers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b15e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch  # type: ignore\n",
    "async def _populate_bg_tasks(\n",
    "    self: FastKafkaAPI,\n",
    ") -> None:\n",
    "    self._bg_task_group_generator = anyio.create_task_group()\n",
    "    self._bg_tasks_group = await self._bg_task_group_generator.__aenter__()\n",
    "    for task in self._scheduled_bg_tasks:\n",
    "        self._bg_tasks_group.start_soon(task)\n",
    "\n",
    "\n",
    "@patch  # type: ignore\n",
    "async def _shutdown_bg_tasks(\n",
    "    self: FastKafkaAPI,\n",
    ") -> None:\n",
    "    self._bg_tasks_group.cancel_scope.cancel()  # type: ignore\n",
    "    await self._bg_task_group_generator.__aexit__(None, None, None)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c687d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = setup_testing_app()\n",
    "await app._populate_bg_tasks()\n",
    "assert len(app._scheduled_bg_tasks) == 1\n",
    "assert app._bg_task_group_generator is not None\n",
    "assert app._bg_tasks_group is not None\n",
    "\n",
    "await app._shutdown_bg_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880411a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch  # type: ignore\n",
    "def generate_async_spec(self: FastKafkaAPI) -> None:\n",
    "    export_async_spec(\n",
    "        consumers={\n",
    "            topic: callback for topic, (callback, _) in self._consumers_store.items()\n",
    "        },\n",
    "        producers={\n",
    "            topic: callback for topic, (callback, _, _) in self._producers_store.items()\n",
    "        },\n",
    "        kafka_brokers=self._kafka_brokers,\n",
    "        kafka_service_info=self._kafka_service_info,\n",
    "        asyncapi_path=self._asyncapi_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a2396d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api._components.asyncapi: Old async specifications at '/tmp/000_FastKafkaAPI/asyncapi/spec/asyncapi.yml' does not exist.\n",
      "[INFO] fast_kafka_api._components.asyncapi: New async specifications generated at: '/tmp/000_FastKafkaAPI/asyncapi/spec/asyncapi.yml'\n",
      "[INFO] fast_kafka_api._components.asyncapi: Async docs generated at '/tmp/000_FastKafkaAPI/asyncapi/docs'\n",
      "[INFO] fast_kafka_api._components.asyncapi: Output of '$ npx -y -p @asyncapi/generator ag /tmp/000_FastKafkaAPI/asyncapi/spec/asyncapi.yml @asyncapi/html-template -o /tmp/000_FastKafkaAPI/asyncapi/docs --force-write'\u001b[32m\n",
      "\n",
      "Done! \u001b[0m\n",
      "\u001b[33mCheck out your shiny new generated files at \u001b[0m\u001b[35m/tmp/000_FastKafkaAPI/asyncapi/docs\u001b[0m\u001b[33m.\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "app = setup_testing_app()\n",
    "app.generate_async_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd84f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch  # type: ignore\n",
    "async def _on_startup(self: FastKafkaAPI) -> None:\n",
    "\n",
    "    self._is_shutting_down = False\n",
    "\n",
    "    def is_shutting_down_f(self: FastKafkaAPI = self) -> bool:\n",
    "        return self._is_shutting_down\n",
    "\n",
    "    self.generate_async_spec()\n",
    "    await self._populate_producers()\n",
    "    self._populate_consumers(is_shutting_down_f)\n",
    "    await self._populate_bg_tasks()\n",
    "\n",
    "\n",
    "@patch  # type: ignore\n",
    "async def _on_shutdown(self: FastKafkaAPI) -> None:\n",
    "    self._is_shutting_down = True\n",
    "\n",
    "    await self._shutdown_bg_tasks()\n",
    "    await self._shutdown_consumers()\n",
    "    await self._shutdown_producers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@asynccontextmanager\n",
    "async def start_test_app():\n",
    "    app = setup_testing_app()\n",
    "    try:\n",
    "        await app._on_startup()\n",
    "        yield app\n",
    "    finally:\n",
    "        await app._on_shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec33cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = \"\"\"asyncapi: 2.5.0\n",
    "info:\n",
    "  description: ''\n",
    "  title: FastAPI\n",
    "  version: 0.1.0\n",
    "  contact:\n",
    "    email: noreply@gmail.com\n",
    "    name: Author\n",
    "    url: https://www.google.com\n",
    "servers:\n",
    "  local:\n",
    "    description: Local (dev) Kafka broker\n",
    "    protocol: kafka\n",
    "    url: kafka\n",
    "    variables:\n",
    "      port:\n",
    "        default: '9092'\n",
    "channels:\n",
    "  my_topic_1:\n",
    "    subscribe:\n",
    "      message:\n",
    "        $ref: '#/components/messages/MyMsgUrl'\n",
    "  my_topic_2:\n",
    "    subscribe:\n",
    "      message:\n",
    "        $ref: '#/components/messages/MyMsgEmail'\n",
    "  my_topic_3:\n",
    "    publish:\n",
    "      message:\n",
    "        $ref: '#/components/messages/MyMsgUrl'\n",
    "  my_topic_4:\n",
    "    publish:\n",
    "      message:\n",
    "        $ref: '#/components/messages/MyMsgEmail'\n",
    "  my_topic_5:\n",
    "    publish:\n",
    "      message:\n",
    "        $ref: '#/components/messages/MyMsgUrl'\n",
    "components:\n",
    "  messages:\n",
    "    MyMsgEmail:\n",
    "      payload:\n",
    "        example:\n",
    "          email: agent-007@sis.gov.uk\n",
    "          msg_url:\n",
    "            info:\n",
    "              mobile: '+385987654321'\n",
    "              name: James Bond\n",
    "            url: https://sis.gov.uk/agents/007\n",
    "        properties:\n",
    "          email:\n",
    "            example: agent-007@sis.gov.uk\n",
    "            format: email\n",
    "            title: Email\n",
    "            type: string\n",
    "          msg_url:\n",
    "            allOf:\n",
    "            - $ref: '#/components/messages/MyMsgUrl'\n",
    "            example:\n",
    "              info:\n",
    "                mobile: '+385987654321'\n",
    "                name: James Bond\n",
    "              url: https://sis.gov.uk/agents/007\n",
    "            title: Msg Url\n",
    "        required:\n",
    "        - msg_url\n",
    "        - email\n",
    "        title: MyMsgEmail\n",
    "        type: object\n",
    "    MyMsgUrl:\n",
    "      payload:\n",
    "        example:\n",
    "          info:\n",
    "            mobile: '+385987654321'\n",
    "            name: James Bond\n",
    "          url: https://sis.gov.uk/agents/007\n",
    "        properties:\n",
    "          info:\n",
    "            allOf:\n",
    "            - $ref: '#/components/schemas/MyInfo'\n",
    "            example:\n",
    "              mobile: '+385987654321'\n",
    "              name: James Bond\n",
    "            title: Info\n",
    "          url:\n",
    "            example: https://sis.gov.uk/agents/007\n",
    "            format: uri\n",
    "            maxLength: 2083\n",
    "            minLength: 1\n",
    "            title: Url\n",
    "            type: string\n",
    "        required:\n",
    "        - info\n",
    "        - url\n",
    "        title: MyMsgUrl\n",
    "        type: object\n",
    "  schemas:\n",
    "    MyInfo:\n",
    "      payload:\n",
    "        properties:\n",
    "          mobile:\n",
    "            example: '+385987654321'\n",
    "            title: Mobile\n",
    "            type: string\n",
    "          name:\n",
    "            example: James Bond\n",
    "            title: Name\n",
    "            type: string\n",
    "        required:\n",
    "        - mobile\n",
    "        - name\n",
    "        title: MyInfo\n",
    "        type: object\n",
    "  securitySchemes: {}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407913e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api._components.asyncapi: Old async specifications at '/tmp/000_FastKafkaAPI/asyncapi/spec/asyncapi.yml' does not exist.\n",
      "[INFO] fast_kafka_api._components.asyncapi: New async specifications generated at: '/tmp/000_FastKafkaAPI/asyncapi/spec/asyncapi.yml'\n",
      "[INFO] fast_kafka_api._components.asyncapi: Async docs generated at '/tmp/000_FastKafkaAPI/asyncapi/docs'\n",
      "[INFO] fast_kafka_api._components.asyncapi: Output of '$ npx -y -p @asyncapi/generator ag /tmp/000_FastKafkaAPI/asyncapi/spec/asyncapi.yml @asyncapi/html-template -o /tmp/000_FastKafkaAPI/asyncapi/docs --force-write'\u001b[32m\n",
      "\n",
      "Done! \u001b[0m\n",
      "\u001b[33mCheck out your shiny new generated files at \u001b[0m\u001b[35m/tmp/000_FastKafkaAPI/asyncapi/docs\u001b[0m\u001b[33m.\u001b[0m\n",
      "\n",
      "\n",
      "[INFO] __main__: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fast-kafka-api-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Entering...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting task group\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting send_stream\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Finished.\n",
      "[INFO] __main__: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fast-kafka-api-kafka-1:9092'}'\n",
      "[INFO] __main__: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fast-kafka-api-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Entering...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting task group\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting send_stream\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'tvrtko-fast-kafka-api-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'tvrtko-fast-kafka-api-kafka-1:9092_group'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'tvrtko-fast-kafka-api-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'tvrtko-fast-kafka-api-kafka-1:9092_group'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'my_topic_1'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'my_topic_1'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'my_topic_2'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'my_topic_2'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1003 for group tvrtko-fast-kafka-api-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group tvrtko-fast-kafka-api-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group tvrtko-fast-kafka-api-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1003 for group tvrtko-fast-kafka-api-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group tvrtko-fast-kafka-api-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group tvrtko-fast-kafka-api-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'tvrtko-fast-kafka-api-kafka-1:9092_group' (generation 25) with member_id aiokafka-0.8.0-50cbf2c1-48bb-4db1-99d5-c22b9613ce83\n",
      "[INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'tvrtko-fast-kafka-api-kafka-1:9092_group' (generation 26) with member_id aiokafka-0.8.0-c59a8bf1-18ec-4d4f-844c-a2fe1244b2fb\n",
      "[INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group tvrtko-fast-kafka-api-kafka-1:9092_group with generation 26\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='my_topic_2', partition=0)} for group tvrtko-fast-kafka-api-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Entering...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting send_stream\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting task group\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Stoping producer...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Finished\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Entering...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting send_stream\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting task group\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Stoping producer...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Finished\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "d1, d2 = None, None\n",
    "\n",
    "\n",
    "async def test_me():\n",
    "    global d1\n",
    "    global d2\n",
    "    async with start_test_app() as app:\n",
    "        client = TestClient(app._fast_api_app)\n",
    "        response = client.get(\"/asyncapi.yml\")\n",
    "        assert response.status_code == 200\n",
    "        d1 = yaml.safe_load(response.text)\n",
    "        d2 = yaml.safe_load(expected)\n",
    "        assert d1 == d2, f\"{d1} != {d2}\"\n",
    "\n",
    "\n",
    "asyncio.run(test_me())\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9cfce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fast-kafka-api-kafka-1:9092'}'\n",
      "[INFO] __main__: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fast-kafka-api-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Entering...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting task group\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting send_stream\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Entering...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting send_stream\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting task group\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Stoping producer...\n",
      "[INFO] fast_kafka_api._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Finished\n"
     ]
    }
   ],
   "source": [
    "# don't wait for specs to be generated (takes 10 sec or so)\n",
    "with unittest.mock.patch(\"__main__.export_async_spec\"):\n",
    "\n",
    "    # mock up send method of AIOKafkaProducer\n",
    "    with mock_AIOKafkaProducer_send() as mock:\n",
    "\n",
    "        app = create_testing_app()\n",
    "\n",
    "        @app.produces()\n",
    "        async def to_my_test_topic(mobile: str, url: str) -> MyMsgUrl:\n",
    "            msg = MyMsgUrl(info=dict(mobile=mobile, name=\"James Bond\"), url=url)\n",
    "            return msg\n",
    "\n",
    "        @app.produces()\n",
    "        def to_my_test_topic_2(mobile: str, url: str) -> MyMsgUrl:\n",
    "            msg = MyMsgUrl(info=dict(mobile=mobile, name=\"James Bond\"), url=url)\n",
    "            return msg\n",
    "\n",
    "        try:\n",
    "            await app._on_startup()\n",
    "            await to_my_test_topic(mobile=\"+385912345678\", url=\"https://www.vip.hr\")\n",
    "            to_my_test_topic_2(mobile=\"+385987654321\", url=\"https://www.ht.hr\")\n",
    "        finally:\n",
    "            await app._on_shutdown()\n",
    "\n",
    "        mock.assert_has_calls(\n",
    "            [\n",
    "                unittest.mock.call(\n",
    "                    \"my_test_topic\",\n",
    "                    b'{\"info\": {\"mobile\": \"+385912345678\", \"name\": \"James Bond\"}, \"url\": \"https://www.vip.hr\"}',\n",
    "                ),\n",
    "                unittest.mock.call(\n",
    "                    \"my_test_topic_2\",\n",
    "                    b'{\"info\": {\"mobile\": \"+385987654321\", \"name\": \"James Bond\"}, \"url\": \"https://www.ht.hr\"}',\n",
    "                ),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b114fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# don't wait for specs to be generated (takes 10 sec or so)\n",
    "with unittest.mock.patch(\"__main__.export_async_spec\"):\n",
    "\n",
    "    app = create_testing_app()\n",
    "    fast_task = unittest.mock.Mock()\n",
    "    long_task = unittest.mock.Mock()\n",
    "\n",
    "    @app.run_in_background()\n",
    "    async def bg_task():\n",
    "        fast_task()\n",
    "        await asyncio.sleep(100)\n",
    "        long_task()\n",
    "\n",
    "    fast_task_second = unittest.mock.Mock()\n",
    "    long_task_second = unittest.mock.Mock()\n",
    "\n",
    "    @app.run_in_background()\n",
    "    async def bg_task_second():\n",
    "        fast_task_second()\n",
    "        await asyncio.sleep(100)\n",
    "        long_task_second()\n",
    "\n",
    "    try:\n",
    "        await app._on_startup()\n",
    "    finally:\n",
    "        await app._on_shutdown()\n",
    "\n",
    "    fast_task.assert_called()\n",
    "    long_task.assert_not_called()\n",
    "\n",
    "    fast_task_second.assert_called()\n",
    "    long_task_second.assert_not_called()\n",
    "    \n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f99375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
