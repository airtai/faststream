{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff734a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c8cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c9007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api.asyncapi: ok\n"
     ]
    }
   ],
   "source": [
    "# | exporti\n",
    "\n",
    "import json\n",
    "import yaml\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from os import environ\n",
    "from enum import Enum\n",
    "import httpx\n",
    "\n",
    "from confluent_kafka import Producer, Consumer\n",
    "from fastapi import status, Depends, HTTPException, Request, Response\n",
    "from fastapi.openapi.docs import get_swagger_ui_html, get_redoc_html\n",
    "from fastapi.openapi.utils import get_openapi\n",
    "from fastapi.responses import FileResponse, RedirectResponse\n",
    "from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from pydantic import validator, BaseModel, Field, HttpUrl, EmailStr, NonNegativeInt\n",
    "\n",
    "from fast_kafka_api.application import FastKafkaAPI, KafkaErrorMsg\n",
    "from fast_kafka_api.asyncapi import KafkaMessage\n",
    "from fast_kafka_api.logger import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eb7517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | include: false\n",
    "\n",
    "import tempfile\n",
    "import asyncio\n",
    "from datetime import timedelta\n",
    "\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from fastapi.testclient import TestClient\n",
    "from starlette.datastructures import Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d9f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a6bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: check\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0303458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ModelType(str, Enum):\n",
    "    churn = \"churn\"\n",
    "    propensity_to_buy = \"propensity_to_buy\"\n",
    "\n",
    "\n",
    "class ModelTrainingRequest(BaseModel):\n",
    "    AccountId: NonNegativeInt = Field(\n",
    "        ..., example=202020, description=\"ID of an account\"\n",
    "    )\n",
    "    ModelName: ModelType = Field(..., example=\"churn\", description=\"ID of an account\")\n",
    "    total_no_of_records: NonNegativeInt = Field(\n",
    "        ...,\n",
    "        example=1_000_000,\n",
    "        description=\"total number of records (rows) to be ingested\",\n",
    "    )\n",
    "\n",
    "\n",
    "# class ModelTrainingResponse(BaseModel):\n",
    "#     training_data_topic: str = Field(\n",
    "#         ...,\n",
    "#         example=\"training_data\",\n",
    "#         description=\"Name of the Kafka topic to send training data to\",\n",
    "#     ),\n",
    "#     training_data_status_topic: str = Field(\n",
    "#         ...,\n",
    "#         example=\"training_data_status_topic\",\n",
    "#         description=\"Name of the Kafka topic to receive training data status from\",\n",
    "#     ),\n",
    "#     prediction_data_topic: str = Field(\n",
    "#         ...,\n",
    "#         example=\"prediction_data\",\n",
    "#         description=\"Name of the Kafka topic to send predictions from\",\n",
    "#     ),\n",
    "#     error_topic: str = Field(\n",
    "#         ...,\n",
    "#         example=\"training_data\",\n",
    "#         description=\"Name of the Kafka topic to send data to\",\n",
    "#     )\n",
    "\n",
    "\n",
    "class EventData(KafkaMessage):\n",
    "    \"\"\"\n",
    "    A sequence of events for a fixed account_id\n",
    "    \"\"\"\n",
    "\n",
    "    AccountId: NonNegativeInt = Field(\n",
    "        ..., example=202020, description=\"ID of an account\"\n",
    "    )\n",
    "    Application: Optional[str] = Field(\n",
    "        None,\n",
    "        example=\"DriverApp\",\n",
    "        description=\"Name of the application in case there is more than one for the AccountId\",\n",
    "    )\n",
    "    DefinitionId: str = Field(\n",
    "        ...,\n",
    "        example=\"appLaunch\",\n",
    "        description=\"name of the event\",\n",
    "        min_length=1,\n",
    "    )\n",
    "    OccurredTime: datetime = Field(\n",
    "        ...,\n",
    "        example=\"2021-03-28T00:34:08\",\n",
    "        description=\"local time of the event\",\n",
    "    )\n",
    "    OccurredTimeTicks: NonNegativeInt = Field(\n",
    "        ...,\n",
    "        example=1616891648496,\n",
    "        description=\"local time of the event as the number of ticks\",\n",
    "    )\n",
    "    PersonId: NonNegativeInt = Field(\n",
    "        ..., example=12345678, description=\"ID of a person\"\n",
    "    )\n",
    "\n",
    "\n",
    "class RealtimeData(KafkaMessage):\n",
    "    event_data: EventData = Field(\n",
    "        ...,\n",
    "        example=dict(\n",
    "            AccountId=202020,\n",
    "            Application=\"DriverApp\",\n",
    "            DefinitionId=\"appLaunch\",\n",
    "            OccurredTime=\"2021-03-28T00:34:08\",\n",
    "            OccurredTimeTicks=1616891648496,\n",
    "            PersonId=12345678,\n",
    "        ),\n",
    "        description=\"realtime event data\",\n",
    "    )\n",
    "    make_prediction: bool = Field(\n",
    "        ..., example=True, description=\"trigger prediction message in prediction topic\"\n",
    "    )\n",
    "\n",
    "\n",
    "class TrainingDataStatus(KafkaMessage):\n",
    "    AccountId: NonNegativeInt = Field(\n",
    "        ..., example=202020, description=\"ID of an account\"\n",
    "    )\n",
    "    no_of_records: NonNegativeInt = Field(\n",
    "        ...,\n",
    "        example=12_345,\n",
    "        description=\"number of records (rows) ingested\",\n",
    "    )\n",
    "    total_no_of_records: NonNegativeInt = Field(\n",
    "        ...,\n",
    "        example=1_000_000,\n",
    "        description=\"total number of records (rows) to be ingested\",\n",
    "    )\n",
    "\n",
    "\n",
    "class TrainingModelStatus(KafkaMessage):\n",
    "    AccountId: NonNegativeInt = Field(\n",
    "        ..., example=202020, description=\"ID of an account\"\n",
    "    )\n",
    "    current_step: NonNegativeInt = Field(\n",
    "        ...,\n",
    "        example=0,\n",
    "        description=\"number of records (rows) ingested\",\n",
    "    )\n",
    "    current_step_percentage: float = Field(\n",
    "        ...,\n",
    "        example=0.21,\n",
    "        description=\"the percentage of the current step completed\",\n",
    "    )\n",
    "    total_no_of_steps: NonNegativeInt = Field(\n",
    "        ...,\n",
    "        example=1_000_000,\n",
    "        description=\"total number of steps for training the model\",\n",
    "    )\n",
    "\n",
    "\n",
    "class ModelMetrics(KafkaMessage):\n",
    "    \"\"\"The standard metrics for classification models.\n",
    "\n",
    "    The most important metrics is AUC for unbalanced classes such as churn. Metrics such as\n",
    "    accuracy are not very useful since they are easily maximized by outputting the most common\n",
    "    class all the time.\n",
    "    \"\"\"\n",
    "\n",
    "    AccountId: NonNegativeInt = Field(\n",
    "        ..., example=202020, description=\"ID of an account\"\n",
    "    )\n",
    "    Application: Optional[str] = Field(\n",
    "        None,\n",
    "        example=\"DriverApp\",\n",
    "        description=\"Name of the application in case there is more than one for the AccountId\",\n",
    "    )\n",
    "    timestamp: datetime = Field(\n",
    "        ...,\n",
    "        example=\"2021-03-28T00:34:08\",\n",
    "        description=\"UTC time when the model was trained\",\n",
    "    )\n",
    "    model_type: ModelType = Field(\n",
    "        ...,\n",
    "        example=\"churn\",\n",
    "        description=\"Name of the model used (churn, propensity to buy)\",\n",
    "    )\n",
    "    auc: float = Field(\n",
    "        ..., example=0.91, description=\"Area under ROC curve\", ge=0.0, le=1.0\n",
    "    )\n",
    "    f1: float = Field(..., example=0.89, description=\"F-1 score\", ge=0.0, le=1.0)\n",
    "    precission: float = Field(\n",
    "        ..., example=0.84, description=\"precission\", ge=0.0, le=1.0\n",
    "    )\n",
    "    recall: float = Field(..., example=0.82, description=\"recall\", ge=0.0, le=1.0)\n",
    "    accuracy: float = Field(..., example=0.82, description=\"accuracy\", ge=0.0, le=1.0)\n",
    "\n",
    "\n",
    "class Prediction(KafkaMessage):\n",
    "    AccountId: NonNegativeInt = Field(\n",
    "        ..., example=202020, description=\"ID of an account\"\n",
    "    )\n",
    "    Application: Optional[str] = Field(\n",
    "        None,\n",
    "        example=\"DriverApp\",\n",
    "        description=\"Name of the application in case there is more than one for the AccountId\",\n",
    "    )\n",
    "    PersonId: NonNegativeInt = Field(\n",
    "        ..., example=12345678, description=\"ID of a person\"\n",
    "    )\n",
    "    prediction_time: datetime = Field(\n",
    "        ...,\n",
    "        example=\"2021-03-28T00:34:08\",\n",
    "        description=\"UTC time of prediction\",\n",
    "    )\n",
    "    model_type: ModelType = Field(\n",
    "        ...,\n",
    "        example=\"churn\",\n",
    "        description=\"Name of the model used (churn, propensity to buy)\",\n",
    "    )\n",
    "    score: float = Field(\n",
    "        ...,\n",
    "        example=0.4321,\n",
    "        description=\"Prediction score (e.g. the probability of churn in the next 28 days)\",\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcd871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Pydantic is accepting extra fields without failing. Fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc9adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "_total_no_of_records = 0\n",
    "_no_of_records_received = 0\n",
    "\n",
    "\n",
    "def create_ws_server(assets_path: Path = Path(\"./assets\")) -> FastKafkaAPI:\n",
    "    title = \"Airt API for Infobip\"\n",
    "    description = \"Airt API for kafka interaction\"\n",
    "    version = \"0.0.1\"\n",
    "    openapi_url = \"/openapi.json\"\n",
    "    favicon_url = \"/assets/images/favicon.ico\"\n",
    "\n",
    "    contact = dict(name=\"airt.ai\", url=\"https://airt.ai\", email=\"info@airt.ai\")\n",
    "\n",
    "    kafka_brokers = {\n",
    "        \"localhost\": {\n",
    "            \"url\": \"kafka\",\n",
    "            \"description\": \"local development kafka\",\n",
    "            \"port\": 9092,\n",
    "        },\n",
    "        \"staging\": {\n",
    "            \"url\": \"kafka.staging.infobip.airt.ai\",\n",
    "            \"description\": \"staging kafka\",\n",
    "            \"port\": 9092,\n",
    "            \"protocol\": \"kafka-secure\",\n",
    "            \"security\": {\"type\": \"plain\"},\n",
    "        },\n",
    "        \"production\": {\n",
    "            \"url\": \"kafka.infobip.airt.ai\",\n",
    "            \"description\": \"production kafka\",\n",
    "            \"port\": 9092,\n",
    "            \"protocol\": \"kafka-secure\",\n",
    "            \"security\": {\"type\": \"plain\"},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
    "    kafka_server_port = environ[\"KAFKA_PORT\"]\n",
    "    kafka_config = {\n",
    "        \"bootstrap.servers\": f\"{kafka_server_url}:{kafka_server_port}\",\n",
    "        \"group.id\": f\"{kafka_server_url}:{kafka_server_port}_group\",\n",
    "        \"auto.offset.reset\": \"earliest\",\n",
    "    }\n",
    "    if \"KAFKA_API_KEY\" in environ:\n",
    "        kafka_config = {\n",
    "            **kafka_config,\n",
    "            **{\n",
    "                \"security.protocol\": \"SASL_SSL\",\n",
    "                \"sasl.mechanisms\": \"PLAIN\",\n",
    "                \"sasl.username\": environ[\"KAFKA_API_KEY\"],\n",
    "                \"sasl.password\": environ[\"KAFKA_API_SECRET\"],\n",
    "            },\n",
    "        }\n",
    "\n",
    "    app = FastKafkaAPI(\n",
    "        title=title,\n",
    "        contact=contact,\n",
    "        kafka_brokers=kafka_brokers,\n",
    "        kafka_config=kafka_config,\n",
    "        description=description,\n",
    "        version=version,\n",
    "        docs_url=None,\n",
    "        redoc_url=None,\n",
    "    )\n",
    "\n",
    "    @app.get(\"/docs\", include_in_schema=False)\n",
    "    def overridden_swagger():\n",
    "        return get_swagger_ui_html(\n",
    "            openapi_url=openapi_url,\n",
    "            title=title,\n",
    "            swagger_favicon_url=favicon_url,\n",
    "        )\n",
    "\n",
    "    @app.get(\"/redoc\", include_in_schema=False)\n",
    "    def overridden_redoc():\n",
    "        return get_redoc_html(\n",
    "            openapi_url=openapi_url,\n",
    "            title=title,\n",
    "            redoc_favicon_url=favicon_url,\n",
    "        )\n",
    "\n",
    "    @app.post(\"/from_kafka_start\")\n",
    "    async def from_kafka_start(training_request: ModelTrainingRequest):\n",
    "        global _total_no_of_records\n",
    "        global _no_of_records_received\n",
    "\n",
    "        _total_no_of_records = training_request.total_no_of_records\n",
    "        _no_of_records_received = 0\n",
    "\n",
    "    @app.get(\"/from_kafka_end\")\n",
    "    async def from_kafka_end():\n",
    "        pass\n",
    "\n",
    "    @app.consumes  # type: ignore\n",
    "    async def on_training_data(msg: EventData):\n",
    "        # ToDo: this is not showing up in logs\n",
    "        logger.debug(f\"msg={msg}\")\n",
    "        global _total_no_of_records\n",
    "        global _no_of_records_received\n",
    "        _no_of_records_received = _no_of_records_received + 1\n",
    "\n",
    "        if _no_of_records_received % 100 == 0:\n",
    "            training_data_status = TrainingDataStatus(\n",
    "                AccountId=EventData.AccountId,\n",
    "                no_of_records=_no_of_records_received,\n",
    "                total_no_of_records=_total_no_of_records,\n",
    "            )\n",
    "            app.produce(\"training_data_status\", training_data_status)\n",
    "\n",
    "    @app.consumes  # type: ignore\n",
    "    async def on_realitime_data(msg: RealtimeData):\n",
    "        pass\n",
    "\n",
    "    @app.produces  # type: ignore\n",
    "    def on_training_data_status(msg: TrainingDataStatus, kafka_msg: Any):\n",
    "        logger.debug(f\"on_training_data_status(msg={msg}, kafka_msg={kafka_msg})\")\n",
    "\n",
    "    @app.produces  # type: ignore\n",
    "    def on_training_model_status(msg: TrainingModelStatus, kafka_msg: Any):\n",
    "        logger.debug(f\"on_training_model_status(msg={msg}, kafka_msg={kafka_msg})\")\n",
    "\n",
    "    @app.produces  # type: ignore\n",
    "    def on_model_metrics(msg: ModelMetrics, kafka_msg: Any):\n",
    "        logger.debug(f\"on_training_model_status(msg={msg}, kafka_msg={kafka_msg})\")\n",
    "\n",
    "    @app.produces  # type: ignore\n",
    "    def on_prediction(msg: Prediction, kafka_msg: Any):\n",
    "        logger.debug(f\"on_realtime_data_status(msg={msg},, kafka_msg={kafka_msg})\")\n",
    "\n",
    "    @app.produces_on_error  # type: ignore\n",
    "    def on_error(kafka_error_msg: KafkaErrorMsg, kafka_err: Any):\n",
    "        logger.warning(f\"on_error(kafka_error_msg={kafka_error_msg}, kafka_err={kafka_err},)\")\n",
    "\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a30de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | include: false\n",
    "def create_fastapi_app(assets_path: Path = Path(\"../assets\")) -> FastKafkaAPI:\n",
    "    assets_path = assets_path.resolve()\n",
    "    app = create_ws_server(assets_path=assets_path)\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f4246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # | include: false\n",
    "\n",
    "\n",
    "# def delivery_report(err, msg):\n",
    "#     \"\"\"Called once for each message produced to indicate delivery result.\n",
    "#     Triggered by poll() or flush().\"\"\"\n",
    "#     if err is not None:\n",
    "#         print(\"Message delivery failed: {}\".format(err))\n",
    "#     else:\n",
    "#         print(\"Message delivered to {} [{}]\".format(msg.topic(), msg.partition()))\n",
    "\n",
    "\n",
    "# app = create_fastapi_app()\n",
    "\n",
    "# # async with app.testing_ctx():\n",
    "# app._on_startup()\n",
    "# client = TestClient(app)\n",
    "# resp = client.get(\"/\")\n",
    "# display(resp)\n",
    "\n",
    "# topic = \"training_data\"\n",
    "# training_data = EventData(\n",
    "#     AccountId=2202200,\n",
    "#     DefinitionId=\"customEvent_1\",\n",
    "#     OccurredTime=\"2021-03-28T01:32:00\",\n",
    "#     OccurredTimeTicks=1616895120245,\n",
    "#     PersonId=22446688,\n",
    "# )\n",
    "# config = {\n",
    "#     \"bootstrap.servers\": f\"{environ['KAFKA_HOSTNAME']}:{environ['KAFKA_PORT']}\"\n",
    "# }\n",
    "# p = Producer(config)\n",
    "\n",
    "# total_messages = 100\n",
    "# for i in range(total_messages):\n",
    "#     p.produce(topic, training_data.json().encode(\"utf-8\"), callback=delivery_report)\n",
    "\n",
    "# error_training_data = training_data.dict()\n",
    "# error_training_data[\"AccountId\"] = False\n",
    "# error_training_data[\"OccurredTime\"] = [1]\n",
    "# p.produce(\n",
    "#     topic, json.dumps(error_training_data).encode(\"utf-8\"), callback=delivery_report\n",
    "# )\n",
    "\n",
    "# p.flush()\n",
    "\n",
    "# await asyncio.sleep(10)\n",
    "\n",
    "# c = Consumer(\n",
    "#     {**config, **{\"group.id\": \"testgroup\", \"auto.offset.reset\": \"earliest\"}}\n",
    "# )\n",
    "# c.subscribe([\"training_data_status\"])\n",
    "# received_messages = 0\n",
    "\n",
    "# start = datetime.now()\n",
    "# expected_messages = 1\n",
    "# while (datetime.now() - start) < timedelta(seconds=20):\n",
    "#     msg = c.poll(1.0)\n",
    "#     if msg is None:\n",
    "#         continue\n",
    "#     if msg.error():\n",
    "#         print(\"Consumer error: {}\".format(msg.error()))\n",
    "#         continue\n",
    "\n",
    "#     print(\"Received message: {}\".format(msg.value().decode(\"utf-8\")))\n",
    "#     received_messages += 1\n",
    "#     if received_messages == total_messages:\n",
    "#         break\n",
    "# if received_messages != expected_messages:\n",
    "#     raise ValueError(f\"received_messages={received_messages} != expected_messages={expected_messages},\")\n",
    "\n",
    "# c.subscribe([\"error\"])\n",
    "# start = datetime.now()\n",
    "# received_error_messages = 0\n",
    "# while (datetime.now() - start) < timedelta(seconds=10):\n",
    "#     msg = c.poll(1.0)\n",
    "#     if msg is None:\n",
    "#         continue\n",
    "#     if msg.error():\n",
    "#         print(\"Consumer error: {}\".format(msg.error()))\n",
    "#         continue\n",
    "\n",
    "#     print(\n",
    "#         \"Received message in on_error topic: {}\".format(msg.value().decode(\"utf-8\"))\n",
    "#     )\n",
    "#     received_error_messages += 1\n",
    "#     break\n",
    "# if received_error_messages != 1:\n",
    "#     raise ValueError(\n",
    "#         f\"Did not receive any messages in on_error topic - received_messages={received_messages}\"\n",
    "#     )\n",
    "# c.close()\n",
    "\n",
    "# await asyncio.sleep(10)\n",
    "\n",
    "# await app._on_shutdown()\n",
    "# await asyncio.sleep(2)\n",
    "# logger.info(\"test completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd909204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | include: false\n",
    "\n",
    "\n",
    "def start_fastapi_server(\n",
    "    assets_path: Path = Path(\"../assets\"),\n",
    "    host: str = \"0.0.0.0\",\n",
    "    port: int = 6006,\n",
    "):\n",
    "    app = create_fastapi_app(assets_path=assets_path)\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=6006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9177ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "# | include: false\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb4faf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [417]\n",
      "INFO:     Waiting for application startup.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api.asyncapi: Async specifications generated at: 'asyncapi/spec/asyncapi.yml'\n",
      "[INFO] fast_kafka_api.asyncapi: Async docs generated at 'asyncapi/docs'\n",
      "[INFO] fast_kafka_api.asyncapi: Output of '$ npx -y -p @asyncapi/generator ag asyncapi/spec/asyncapi.yml @asyncapi/html-template -o asyncapi/docs --force-write'npm WARN deprecated har-validator@5.1.5: this library is no longer supported\n",
      "npm WARN deprecated uuid@3.4.0: Please upgrade  to version 7 or higher.  Older versions may use Math.random() in certain circumstances, which is known to be problematic.  See https://v8.dev/blog/math-random for details.\n",
      "npm WARN deprecated request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142\n",
      "npm WARN deprecated readdir-scoped-modules@1.1.0: This functionality has been moved to @npmcli/fs\n",
      "npm WARN deprecated @npmcli/move-file@1.1.2: This functionality has been moved to @npmcli/fs\n",
      "npm WARN deprecated mkdirp@0.3.5: Legacy versions of mkdirp are no longer supported. Please update to mkdirp 1.x. (Note that the API surface has changed to use Promises in 1.x.)\n",
      "npm WARN deprecated mkdirp@0.3.5: Legacy versions of mkdirp are no longer supported. Please update to mkdirp 1.x. (Note that the API surface has changed to use Promises in 1.x.)\n",
      "\u001b[32m\n",
      "\n",
      "Done! âœ¨\u001b[0m\n",
      "\u001b[33mCheck out your shiny new generated files at \u001b[0m\u001b[35m/tf/fast-kafka-api/notebooks/asyncapi/docs\u001b[0m\u001b[33m.\u001b[0m\n",
      "\n",
      "npm notice \n",
      "npm notice New major version of npm available! 8.19.2 -> 9.1.3\n",
      "npm notice Changelog: <https://github.com/npm/cli/releases/tag/v9.1.3>\n",
      "npm notice Run `npm install -g npm@9.1.3` to update!\n",
      "npm notice \n",
      "\n",
      "[INFO] fast_kafka_api.application: consumers_async_loop(): Kafka admin created <confluent_kafka.admin.AdminClient object>.\n",
      "[INFO] fast_kafka_api.confluent_kafka: create_missing_topics(['error', 'model_metrics', 'prediction', 'realitime_data', 'training_data', 'training_data_status', 'training_model_status']): new_topics = [NewTopic(topic=error,num_partitions=1), NewTopic(topic=model_metrics,num_partitions=1), NewTopic(topic=prediction,num_partitions=1), NewTopic(topic=realitime_data,num_partitions=1), NewTopic(topic=training_data,num_partitions=1), NewTopic(topic=training_data_status,num_partitions=1), NewTopic(topic=training_model_status,num_partitions=1)]\n",
      "[INFO] fast_kafka_api.application: consumers_async_loop(): Kafka topics ['error', 'model_metrics', 'prediction', 'realitime_data', 'training_data', 'training_data_status', 'training_model_status'] created if needed.\n",
      "[INFO] fast_kafka_api.application: AIOProducer created.\n",
      "[INFO] fast_kafka_api.application: consumers_async_loop(topic='training_data', config={'bootstrap.servers': 'davor-kafka:9092', 'group.id': 'davor-kafka:9092_group', 'auto.offset.reset': 'earliest'}, timeout=1.0) starting.\n",
      "[INFO] fast_kafka_api.application: consumers_async_loop(topic='training_data'): Kafka Consumer for topic created.\n",
      "[INFO] fast_kafka_api.application: consumers_async_loop(topic='training_data'): Kafka Consumer subscribed to topic.\n",
      "[INFO] fast_kafka_api.application: consumers_async_loop(topic='realitime_data', config={'bootstrap.servers': 'davor-kafka:9092', 'group.id': 'davor-kafka:9092_group', 'auto.offset.reset': 'earliest'}, timeout=1.0) starting.\n",
      "[INFO] fast_kafka_api.application: consumers_async_loop(topic='realitime_data'): Kafka Consumer for topic created.\n",
      "[INFO] fast_kafka_api.application: consumers_async_loop(topic='realitime_data'): Kafka Consumer subscribed to topic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:6006 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     172.19.0.1:50396 - \"GET / HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     172.19.0.1:50396 - \"GET /asyncapi HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     172.19.0.1:50396 - \"GET /index.html HTTP/1.1\" 200 OK\n",
      "INFO:     172.19.0.1:50394 - \"GET /css/asyncapi.min.css HTTP/1.1\" 200 OK\n",
      "INFO:     172.19.0.1:50410 - \"GET /css/global.min.css HTTP/1.1\" 200 OK\n",
      "INFO:     172.19.0.1:50394 - \"GET /js/asyncapi-ui.min.js HTTP/1.1\" 200 OK\n",
      "INFO:     172.19.0.1:52828 - \"GET /redoc HTTP/1.1\" 200 OK\n",
      "INFO:     172.19.0.1:52828 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "INFO:     172.19.0.1:52828 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     172.19.0.1:52828 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api.application: consumers_async_loop(topic='training_data') shutting down...\n",
      "[INFO] fast_kafka_api.application: consumers_async_loop(topic='training_data'): Kafka Consumer closed.\n",
      "[INFO] fast_kafka_api.application: consumers_async_loop(topic='training_data') exiting.\n",
      "[INFO] fast_kafka_api.application: consumers_async_loop(topic='realitime_data') shutting down...\n",
      "[INFO] fast_kafka_api.application: consumers_async_loop(topic='realitime_data'): Kafka Consumer closed.\n",
      "[INFO] fast_kafka_api.application: consumers_async_loop(topic='realitime_data') exiting.\n",
      "[INFO] fast_kafka_api.application: AIOProducer closed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [417]\n"
     ]
    }
   ],
   "source": [
    "# | eval: false\n",
    "# | include: false\n",
    "\n",
    "start_fastapi_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd38c748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
