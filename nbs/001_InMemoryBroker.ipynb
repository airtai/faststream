{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e3e7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _testing.in_memory_broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78dd1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import uuid\n",
    "from collections import namedtuple\n",
    "from dataclasses import dataclass\n",
    "from contextlib import contextmanager\n",
    "import inspect\n",
    "import asyncio\n",
    "import copy\n",
    "\n",
    "from typing import *\n",
    "import fastkafka._application.app\n",
    "import fastkafka._components.aiokafka_consumer_loop\n",
    "import fastkafka._components.aiokafka_producer_manager\n",
    "from aiokafka import AIOKafkaConsumer, AIOKafkaProducer\n",
    "from aiokafka.structs import ConsumerRecord, TopicPartition, RecordMetadata\n",
    "\n",
    "import fastkafka._application.app\n",
    "from fastkafka._components.meta import copy_func, patch, delegates, classcontextmanager\n",
    "from fastkafka._components.logger import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df56c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import asynccontextmanager\n",
    "import unittest\n",
    "\n",
    "import pytest\n",
    "\n",
    "from fastkafka.testing import ApacheKafkaBroker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e65cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e8c6f7",
   "metadata": {},
   "source": [
    "# Local Kafka broker\n",
    "> In-memory mockup of Kafka broker protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7596402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def create_consumer_record(topic: str, msg: bytes) -> ConsumerRecord: # type: ignore\n",
    "    record = ConsumerRecord(\n",
    "        topic=topic,\n",
    "        partition=0,\n",
    "        offset=0,\n",
    "        timestamp=0,\n",
    "        timestamp_type=0,\n",
    "        key=None,\n",
    "        value=msg,\n",
    "        checksum=0,\n",
    "        serialized_key_size=0,\n",
    "        serialized_value_size=0,\n",
    "        headers=[],\n",
    "    )\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5791221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = create_consumer_record(\"my_topic\", b\"my_msg\")\n",
    "record.partition = 1\n",
    "assert record.partition == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "727d487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ConsumerMetadata:\n",
    "    topic: str\n",
    "    offset: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6ec35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_meta = ConsumerMetadata(\"my_topic\", 0)\n",
    "assert consumer_meta.topic == \"my_topic\"\n",
    "assert consumer_meta.offset == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5737f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "# InMemoryBroker\n",
    "@classcontextmanager()\n",
    "class InMemoryBroker:\n",
    "    def __init__(self, topics: Set[str]):\n",
    "        self.data: Dict[str, List[ConsumerRecord]] = {topic: list() for topic in topics}  # type: ignore\n",
    "        self.consumers_metadata: Dict[uuid.UUID, List[ConsumerMetadata]] = {}\n",
    "        self.is_started: bool = False\n",
    "\n",
    "    def connect(self) -> uuid.UUID:\n",
    "        return uuid.uuid4()\n",
    "\n",
    "    def subscribe(self, actor_id: uuid.UUID, *, auto_offest_reset: str, topic: str) -> None:\n",
    "        consumer_metadata = self.consumers_metadata.get(actor_id, list())\n",
    "        # todo: what if whatever?\n",
    "        consumer_metadata.append(\n",
    "            ConsumerMetadata(\n",
    "                topic, len(self.data[topic]) if auto_offest_reset == \"latest\" else 0\n",
    "            )\n",
    "        )\n",
    "        self.consumers_metadata[actor_id] = consumer_metadata\n",
    "\n",
    "    def unsubscribe(self, actor_id: uuid.UUID) -> None:\n",
    "        try:\n",
    "            del self.consumers_metadata[actor_id]\n",
    "        except KeyError:\n",
    "            logger.warning(f\"No subscription with {actor_id=} found!\")\n",
    "\n",
    "    def produce(  # type: ignore\n",
    "        self, *, topic: str, msg: bytes, key: Optional[bytes] = None\n",
    "    ) -> RecordMetadata:\n",
    "        if topic in self.data:\n",
    "            record = create_consumer_record(topic, msg)\n",
    "            self.data[topic].append(record)\n",
    "        else:\n",
    "            # todo: log only once\n",
    "            logger.warning(\n",
    "                f\"Topic {topic} is not available during auto-create initialization\"\n",
    "            )\n",
    "        return RecordMetadata(\n",
    "            topic=topic,\n",
    "            partition=0,\n",
    "            topic_partition=TopicPartition(topic=topic, partition=0),\n",
    "            offset=0,\n",
    "            timestamp=1680602752070,\n",
    "            timestamp_type=0,\n",
    "            log_start_offset=0,\n",
    "        )\n",
    "\n",
    "    def consume(  # type: ignore\n",
    "        self, actor_id: uuid.UUID\n",
    "    ) -> Dict[TopicPartition, List[ConsumerRecord]]:\n",
    "        msgs: Dict[TopicPartition, List[ConsumerRecord]] = {}  # type: ignore\n",
    "\n",
    "        consumer_metadata = self.consumers_metadata[actor_id]\n",
    "\n",
    "        for metadata in consumer_metadata:\n",
    "            try:\n",
    "                msgs[TopicPartition(metadata.topic, 0)] = self.data[metadata.topic][\n",
    "                    metadata.offset :\n",
    "                ]\n",
    "                metadata.offset = len(self.data[metadata.topic])\n",
    "            except KeyError:\n",
    "                raise RuntimeError(\n",
    "                    f\"{metadata.topic=} not found, did you pass it to InMemoryBroker on init to be created?\"\n",
    "                )\n",
    "        return msgs\n",
    "\n",
    "    @contextmanager\n",
    "    def lifecycle(self) -> Iterator[\"InMemoryBroker\"]:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    async def _start(self) -> str:\n",
    "        logger.info(\"InMemoryBroker._start() called\")\n",
    "        self.__enter__() # type: ignore\n",
    "        return \"localbroker:0\"\n",
    "\n",
    "    async def _stop(self) -> None:\n",
    "        logger.info(\"InMemoryBroker._stop() called\")\n",
    "        self.__exit__(None, None, None) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c59295ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ExceptionInfo KeyError(UUID('b47b4815-c963-4bd9-97a4-c69c7780c140')) tblen=2>\n",
      "[WARNING] __main__: Topic not_my_topic is not available during auto-create initialization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RecordMetadata(topic='not_my_topic', partition=0, topic_partition=TopicPartition(topic='not_my_topic', partition=0), offset=0, timestamp=1680602752070, timestamp_type=0, log_start_offset=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_memory_broker = InMemoryBroker([\"my_topic\"])\n",
    "\n",
    "actor_id = in_memory_broker.connect()\n",
    "\n",
    "with pytest.raises(KeyError) as e:\n",
    "    in_memory_broker.consume(actor_id)\n",
    "    \n",
    "print(e)\n",
    "\n",
    "in_memory_broker.subscribe(actor_id=actor_id, auto_offest_reset=\"earliest\", topic=\"my_topic\")\n",
    "\n",
    "msg = in_memory_broker.consume(actor_id)\n",
    "assert msg == {TopicPartition(topic='my_topic', partition=0): []}, msg\n",
    "\n",
    "# with raise()\n",
    "in_memory_broker.produce(topic=\"not_my_topic\", msg=b\"not my message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88761db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): entering...\n",
      "[WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): (<_UnixSelectorEventLoop running=True closed=False debug=False>) is already running!\n",
      "[WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): calling nest_asyncio.apply()\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: <class 'fastkafka.testing.ApacheKafkaBroker'>.start(): returning 127.0.0.1:9092\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): exited.\n",
      "[WARNING] aiokafka.cluster: Topic not_my_topic is not available during auto-create initialization\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): entering...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 464987...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 464987 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 464608...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 464608 terminated.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): exited.\n"
     ]
    }
   ],
   "source": [
    "#| notest\n",
    "\n",
    "with ApacheKafkaBroker([\"my_topic\"], apply_nest_asyncio=True) as bootstrap_servers:\n",
    "    producer = AIOKafkaProducer(bootstrap_servers=bootstrap_servers)\n",
    "    await producer.start()\n",
    "    for _ in range(1000):\n",
    "        record = await producer.send(topic=\"not_my_topic\", value=b\"not my message\")\n",
    "    await producer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24dcfab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): entering...\n",
      "[WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): (<_UnixSelectorEventLoop running=True closed=False debug=False>) is already running!\n",
      "[WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): calling nest_asyncio.apply()\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: <class 'fastkafka.testing.ApacheKafkaBroker'>.start(): returning 127.0.0.1:9092\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): exited.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'my_topic'})\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'my_topic': 1}. \n",
      "getmany()...\n",
      "exiting...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): entering...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 466343...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 466343 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 465964...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 465964 terminated.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): exited.\n"
     ]
    }
   ],
   "source": [
    "#| notest\n",
    "\n",
    "with ApacheKafkaBroker([\"my_topic\"], apply_nest_asyncio=True) as bootstrap_servers:\n",
    "    consumer = AIOKafkaConsumer(\"my_topic\", bootstrap_servers=bootstrap_servers)\n",
    "    await consumer.start()\n",
    "    print(\"getmany()...\")\n",
    "    msg = await consumer.getmany(timeout_ms=0)\n",
    "    print(\"exiting...\")\n",
    "    await consumer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c5b3a9",
   "metadata": {},
   "source": [
    "## Consumer patching\n",
    "\n",
    "We need to patch AIOKafkaConsumer methods so that we can redirect the consumer to our local kafka broker.\n",
    "\n",
    "Patched methods:\n",
    "\n",
    "- [x] \\_\\_init\\_\\_\n",
    "- [x] start\n",
    "- [x] subscribe\n",
    "- [x] stop\n",
    "- [x] getmany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c85ca42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "# InMemoryConsumer\n",
    "class InMemoryConsumer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        broker: InMemoryBroker,\n",
    "    ) -> None:\n",
    "        logger.info(\"AIOKafkaConsumer patched __init__() called()\")\n",
    "        self.broker = broker\n",
    "        self._id: Optional[uuid.UUID] = None\n",
    "        self._auto_offset_reset: str = \"latest\"\n",
    "\n",
    "    @delegates(AIOKafkaConsumer)\n",
    "    def __call__(\n",
    "        self, \n",
    "        **kwargs: Any\n",
    "    ) -> \"InMemoryConsumer\":        \n",
    "        # todo: function\n",
    "        defaults = {k: v.default for k, v in inspect.signature(InMemoryConsumer.__call__).parameters.items()}\n",
    "        defaults.update(kwargs)\n",
    "        kwargs_with_defaults = defaults\n",
    "        \n",
    "        consume_copy = InMemoryConsumer(self.broker)\n",
    "        consume_copy._auto_offset_reset = kwargs_with_defaults[\"auto_offset_reset\"]\n",
    "        return consume_copy\n",
    "\n",
    "    @delegates(AIOKafkaConsumer.start)\n",
    "    async def start(self, **kwargs: Any) -> None:\n",
    "        pass\n",
    "\n",
    "    @delegates(AIOKafkaConsumer.stop)\n",
    "    async def stop(self, **kwargs: Any) -> None:\n",
    "        pass\n",
    "\n",
    "    @delegates(AIOKafkaConsumer.subscribe)\n",
    "    def subscribe(self, topics: List[str], **kwargs: Any) -> None:\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    @delegates(AIOKafkaConsumer.getmany)\n",
    "    async def getmany( # type: ignore\n",
    "        self, **kwargs: Any\n",
    "    ) -> Dict[TopicPartition, List[ConsumerRecord]]:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "677208e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "{}\n",
      "{'self': <class 'inspect._empty'>, 'loop': None, 'bootstrap_servers': 'localhost', 'client_id': 'aiokafka-0.8.0', 'group_id': None, 'key_deserializer': None, 'value_deserializer': None, 'fetch_max_wait_ms': 500, 'fetch_max_bytes': 52428800, 'fetch_min_bytes': 1, 'max_partition_fetch_bytes': 1048576, 'request_timeout_ms': 40000, 'retry_backoff_ms': 100, 'auto_offset_reset': 'latest', 'enable_auto_commit': True, 'auto_commit_interval_ms': 5000, 'check_crcs': True, 'metadata_max_age_ms': 300000, 'partition_assignment_strategy': (<class 'kafka.coordinator.assignors.roundrobin.RoundRobinPartitionAssignor'>,), 'max_poll_interval_ms': 300000, 'rebalance_timeout_ms': None, 'session_timeout_ms': 10000, 'heartbeat_interval_ms': 3000, 'consumer_timeout_ms': 200, 'max_poll_records': None, 'ssl_context': None, 'security_protocol': 'PLAINTEXT', 'api_version': 'auto', 'exclude_internal_topics': True, 'connections_max_idle_ms': 540000, 'isolation_level': 'read_uncommitted', 'sasl_mechanism': 'PLAIN', 'sasl_plain_password': None, 'sasl_plain_username': None, 'sasl_kerberos_service_name': 'kafka', 'sasl_kerberos_domain_name': None, 'sasl_oauth_token_provider': None, 'kwargs': <class 'inspect._empty'>}\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "{'auto_offset_reset': 'earliest'}\n",
      "{'self': <class 'inspect._empty'>, 'loop': None, 'bootstrap_servers': 'localhost', 'client_id': 'aiokafka-0.8.0', 'group_id': None, 'key_deserializer': None, 'value_deserializer': None, 'fetch_max_wait_ms': 500, 'fetch_max_bytes': 52428800, 'fetch_min_bytes': 1, 'max_partition_fetch_bytes': 1048576, 'request_timeout_ms': 40000, 'retry_backoff_ms': 100, 'auto_offset_reset': 'earliest', 'enable_auto_commit': True, 'auto_commit_interval_ms': 5000, 'check_crcs': True, 'metadata_max_age_ms': 300000, 'partition_assignment_strategy': (<class 'kafka.coordinator.assignors.roundrobin.RoundRobinPartitionAssignor'>,), 'max_poll_interval_ms': 300000, 'rebalance_timeout_ms': None, 'session_timeout_ms': 10000, 'heartbeat_interval_ms': 3000, 'consumer_timeout_ms': 200, 'max_poll_records': None, 'ssl_context': None, 'security_protocol': 'PLAINTEXT', 'api_version': 'auto', 'exclude_internal_topics': True, 'connections_max_idle_ms': 540000, 'isolation_level': 'read_uncommitted', 'sasl_mechanism': 'PLAIN', 'sasl_plain_password': None, 'sasl_plain_username': None, 'sasl_kerberos_service_name': 'kafka', 'sasl_kerberos_domain_name': None, 'sasl_oauth_token_provider': None, 'kwargs': <class 'inspect._empty'>}\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "{'auto_offset_reset': 'whatever'}\n",
      "{'self': <class 'inspect._empty'>, 'loop': None, 'bootstrap_servers': 'localhost', 'client_id': 'aiokafka-0.8.0', 'group_id': None, 'key_deserializer': None, 'value_deserializer': None, 'fetch_max_wait_ms': 500, 'fetch_max_bytes': 52428800, 'fetch_min_bytes': 1, 'max_partition_fetch_bytes': 1048576, 'request_timeout_ms': 40000, 'retry_backoff_ms': 100, 'auto_offset_reset': 'whatever', 'enable_auto_commit': True, 'auto_commit_interval_ms': 5000, 'check_crcs': True, 'metadata_max_age_ms': 300000, 'partition_assignment_strategy': (<class 'kafka.coordinator.assignors.roundrobin.RoundRobinPartitionAssignor'>,), 'max_poll_interval_ms': 300000, 'rebalance_timeout_ms': None, 'session_timeout_ms': 10000, 'heartbeat_interval_ms': 3000, 'consumer_timeout_ms': 200, 'max_poll_records': None, 'ssl_context': None, 'security_protocol': 'PLAINTEXT', 'api_version': 'auto', 'exclude_internal_topics': True, 'connections_max_idle_ms': 540000, 'isolation_level': 'read_uncommitted', 'sasl_mechanism': 'PLAIN', 'sasl_plain_password': None, 'sasl_plain_username': None, 'sasl_kerberos_service_name': 'kafka', 'sasl_kerberos_domain_name': None, 'sasl_oauth_token_provider': None, 'kwargs': <class 'inspect._empty'>}\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[ERROR] asyncio: Unclosed AIOKafkaConsumer\n",
      "consumer: <aiokafka.consumer.consumer.AIOKafkaConsumer object at 0x7f0240084890>\n",
      "[ERROR] asyncio: Unclosed AIOKafkaConsumer\n",
      "consumer: <aiokafka.consumer.consumer.AIOKafkaConsumer object at 0x7f0212843790>\n"
     ]
    }
   ],
   "source": [
    "broker = InMemoryBroker([\"topic\"])\n",
    "\n",
    "ConsumerClass = InMemoryConsumer(broker)\n",
    "\n",
    "for cls in [ConsumerClass, AIOKafkaConsumer]:\n",
    "\n",
    "    consumer = cls()\n",
    "    assert consumer._auto_offset_reset == \"latest\"\n",
    "\n",
    "    consumer = cls(auto_offset_reset=\"earliest\")\n",
    "    assert consumer._auto_offset_reset == \"earliest\"\n",
    "\n",
    "    consumer = cls(auto_offset_reset=\"whatever\")\n",
    "    assert consumer._auto_offset_reset == \"whatever\"\n",
    "    \n",
    "    await consumer.stop()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e4df06",
   "metadata": {},
   "source": [
    "Patching start so that we don't try to start the real AIOKafkaConsumer instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f53f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "@delegates(AIOKafkaConsumer.start)\n",
    "async def start(self: InMemoryConsumer, **kwargs: Any) -> None:\n",
    "    logger.info(\"AIOKafkaConsumer patched start() called()\")\n",
    "    if self._id is not None:\n",
    "        raise RuntimeError(\n",
    "            \"Consumer start() already called! Run consumer stop() before running start() again\"\n",
    "        )\n",
    "    self._id = self.broker.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072dd1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched start() called()\n"
     ]
    }
   ],
   "source": [
    "broker = InMemoryBroker([\"my_topic\"])\n",
    "\n",
    "ConsumerClass = InMemoryConsumer(broker)\n",
    "\n",
    "for cls in [ConsumerClass]:\n",
    "\n",
    "    consumer = cls()\n",
    "    await consumer.start()\n",
    "    await consumer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c11cd3",
   "metadata": {},
   "source": [
    "Patching subscribe so that we can connect to our Local, in-memory, Kafka broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de72311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "@delegates(AIOKafkaConsumer.subscribe)\n",
    "def subscribe(self: InMemoryConsumer, topics: List[str], **kwargs: Any) -> None:\n",
    "    logger.info(\"AIOKafkaConsumer patched subscribe() called\")\n",
    "    if self._id is None:\n",
    "        raise RuntimeError(\"Consumer start() not called! Run consumer start() first\")\n",
    "    logger.info(f\"AIOKafkaConsumer.subscribe(), subscribing to: {topics}\")\n",
    "    for topic in topics:\n",
    "        self.broker.subscribe(\n",
    "            self._id, topic=topic, auto_offest_reset=self._auto_offset_reset\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e08d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched start() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['my_topic']\n"
     ]
    }
   ],
   "source": [
    "broker = InMemoryBroker(topics=[\"my_topic\"])\n",
    "\n",
    "ConsumerClass = InMemoryConsumer(broker)\n",
    "consumer = ConsumerClass()\n",
    "\n",
    "await consumer.start()\n",
    "consumer.subscribe([\"my_topic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd80a4d5",
   "metadata": {},
   "source": [
    "Patching stop so that be dont break anything by calling the real AIOKafkaConsumer stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@patch\n",
    "@delegates(AIOKafkaConsumer.stop)\n",
    "async def stop(self: InMemoryConsumer, **kwargs: Any) -> None:\n",
    "    logger.info(\"AIOKafkaConsumer patched stop() called\")\n",
    "    if self._id is None:\n",
    "        raise RuntimeError(\n",
    "            \"Consumer start() not called! Run consumer start() first\"\n",
    "        )\n",
    "    self.broker.unsubscribe(self._id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc667214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched start() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['my_topic']\n",
      "[INFO] __main__: AIOKafkaConsumer patched stop() called\n"
     ]
    }
   ],
   "source": [
    "broker = InMemoryBroker(topics=[\"my_topic\"])\n",
    "    \n",
    "ConsumerClass = InMemoryConsumer(broker)\n",
    "consumer = ConsumerClass()\n",
    "\n",
    "await consumer.start()\n",
    "consumer.subscribe([\"my_topic\"])\n",
    "await consumer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c733b4",
   "metadata": {},
   "source": [
    "Patching getmany so that the messages are pulled from our Local, in-memory, Kafka broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0663c9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@patch\n",
    "@delegates(AIOKafkaConsumer.getmany)\n",
    "async def getmany( # type: ignore\n",
    "    self: InMemoryConsumer, **kwargs: Any\n",
    ") -> Dict[TopicPartition, List[ConsumerRecord]]:\n",
    "    return self.broker.consume(self._id) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4940bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched start() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['my_topic']\n",
      "[INFO] __main__: AIOKafkaConsumer patched stop() called\n"
     ]
    }
   ],
   "source": [
    "broker = InMemoryBroker(topics=[\"my_topic\"])\n",
    "\n",
    "ConsumerClass = InMemoryConsumer(broker)\n",
    "consumer = ConsumerClass(auto_offset_reset=\"latest\")\n",
    "\n",
    "await consumer.start()\n",
    "\n",
    "consumer.subscribe([\"my_topic\"])\n",
    "await consumer.getmany()\n",
    "\n",
    "await consumer.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723468f0",
   "metadata": {},
   "source": [
    "## Producer patching\n",
    "\n",
    "We need to patch AIOKafkaProducer methods so that we can redirect the producer to our local kafka broker\n",
    "\n",
    "- [x] \\_\\_init\\_\\_\n",
    "- [x] start\n",
    "- [x] stop\n",
    "- [x] send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class InMemoryProducer:\n",
    "    def __init__(self, broker: InMemoryBroker, **kwargs: Any) -> None:\n",
    "        logger.info(\"AIOKafkaProducer patched __init__() called()\")\n",
    "        self.broker = broker\n",
    "        self.id: Optional[uuid.UUID] = None\n",
    "\n",
    "    @delegates(AIOKafkaProducer)\n",
    "    def __call__(self, **kwargs: Any) -> \"InMemoryProducer\":\n",
    "        return InMemoryProducer(self.broker)\n",
    "\n",
    "    @delegates(AIOKafkaProducer.start)\n",
    "    async def start(self, **kwargs: Any) -> None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @delegates(AIOKafkaProducer.stop)\n",
    "    async def stop(self, **kwargs: Any) -> None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @delegates(AIOKafkaProducer.send)\n",
    "    async def send(  # type: ignore\n",
    "        self: AIOKafkaProducer,\n",
    "        topic: str,\n",
    "        msg: bytes,\n",
    "        key: Optional[bytes] = None,\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf322a",
   "metadata": {},
   "source": [
    "Patching AIOKafkaProducer start so that we mock the startup procedure of AIOKafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ac5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch # type: ignore\n",
    "@delegates(AIOKafkaProducer.start)\n",
    "async def start(self: InMemoryProducer, **kwargs: Any) -> None:\n",
    "    logger.info(\"AIOKafkaProducer patched start() called()\")\n",
    "    if self.id is not None:\n",
    "        raise RuntimeError(\n",
    "            \"Producer start() already called! Run producer stop() before running start() again\"\n",
    "        )\n",
    "    self.id = self.broker.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f250c614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched start() called()\n"
     ]
    }
   ],
   "source": [
    "broker = InMemoryBroker(topics=[\"my_topic\"])\n",
    "\n",
    "ProducerClass = InMemoryProducer(broker)\n",
    "producer = ProducerClass()\n",
    "\n",
    "await producer.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e9be9",
   "metadata": {},
   "source": [
    "Patching AIOKafkaProducerStop so that we don't uniintentionally try to stop a real instance of AIOKafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32412969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch # type: ignore\n",
    "@delegates(AIOKafkaProducer.stop)\n",
    "async def stop(self: InMemoryProducer, **kwargs: Any) -> None:\n",
    "    logger.info(\"AIOKafkaProducer patched stop() called\")\n",
    "    if self.id is None:\n",
    "        raise RuntimeError(\n",
    "            \"Producer start() not called! Run producer start() first\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4a1fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched start() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched stop() called\n"
     ]
    }
   ],
   "source": [
    "broker = InMemoryBroker(topics=[\"my_topic\"])\n",
    "\n",
    "ProducerClass = InMemoryProducer(broker)\n",
    "producer = ProducerClass()\n",
    "\n",
    "await producer.start()\n",
    "await producer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c77a56",
   "metadata": {},
   "source": [
    "Patching AIOKafkaProducer send so that we redirect sent messages to Local, in-memory, Kafka broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f42a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "@delegates(AIOKafkaProducer.send)\n",
    "async def send( # type: ignore\n",
    "    self: InMemoryProducer,\n",
    "    topic: str,\n",
    "    msg: bytes,\n",
    "    key: Optional[bytes] = None,\n",
    "    **kwargs: Any,\n",
    "): #asyncio.Task[ConsumerRecord]\n",
    "    if self.id is None:\n",
    "        raise RuntimeError(\n",
    "            \"Producer start() not called! Run producer start() first\"\n",
    "        )\n",
    "    record = self.broker.produce(topic=topic, msg=msg, key=key)\n",
    "\n",
    "    async def _f(record: ConsumerRecord = record) -> ConsumerRecord: # type: ignore\n",
    "        return record\n",
    "\n",
    "    return asyncio.create_task(_f())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fda1d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched start() called()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RecordMetadata(topic='my_topic', partition=0, topic_partition=TopicPartition(topic='my_topic', partition=0), offset=0, timestamp=1680602752070, timestamp_type=0, log_start_offset=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broker = InMemoryBroker(topics=[\"my_topic\"])\n",
    "\n",
    "ProducerClass = InMemoryProducer(broker)\n",
    "producer = ProducerClass()\n",
    "\n",
    "await producer.start()\n",
    "msg_fut = await producer.send(\"my_topic\", b\"some_msg\")\n",
    "await msg_fut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e4d12b",
   "metadata": {},
   "source": [
    "## Add patching to InMemoryBroker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "@contextmanager\n",
    "def lifecycle(self: InMemoryBroker) -> Iterator[InMemoryBroker]:\n",
    "    logger.info(\n",
    "        \"InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!\"\n",
    "    )\n",
    "    try:\n",
    "        logger.info(\"InMemoryBroker starting\")\n",
    "        \n",
    "        old_consumer_app = fastkafka._application.app.AIOKafkaConsumer\n",
    "        old_producer_app = fastkafka._application.app.AIOKafkaProducer\n",
    "        old_consumer_loop = fastkafka._components.aiokafka_consumer_loop.AIOKafkaConsumer\n",
    "        old_producer_manager = fastkafka._components.aiokafka_producer_manager.AIOKafkaProducer\n",
    "        \n",
    "        fastkafka._application.app.AIOKafkaConsumer = InMemoryConsumer(self)\n",
    "        fastkafka._application.app.AIOKafkaProducer = InMemoryProducer(self)\n",
    "        fastkafka._components.aiokafka_consumer_loop.AIOKafkaConsumer = InMemoryConsumer(self)\n",
    "        fastkafka._components.aiokafka_producer_manager.AIOKafkaProducer = InMemoryProducer(self)\n",
    "        \n",
    "        self.is_started = True\n",
    "        yield self\n",
    "    finally:\n",
    "        logger.info(\"InMemoryBroker stopping\")\n",
    "        \n",
    "        fastkafka._application.app.AIOKafkaConsumer = old_consumer_app\n",
    "        fastkafka._application.app.AIOKafkaProducer = old_producer_app\n",
    "        fastkafka._components.aiokafka_consumer_loop.AIOKafkaConsumer = old_consumer_loop\n",
    "        fastkafka._components.aiokafka_producer_manager.AIOKafkaProducer = old_producer_manager\n",
    "        \n",
    "        self.is_started = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc55ccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.InMemoryBroker'>.__enter__\n",
      "[INFO] __main__: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "[INFO] __main__: InMemoryBroker starting\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "<class '__main__.InMemoryBroker'>.__exit__\n",
      "[INFO] __main__: InMemoryBroker stopping\n"
     ]
    }
   ],
   "source": [
    "assert fastkafka._application.app.AIOKafkaConsumer == AIOKafkaConsumer\n",
    "assert fastkafka._application.app.AIOKafkaProducer == AIOKafkaProducer\n",
    "\n",
    "with InMemoryBroker([\"topic\"]) as broker:\n",
    "    assert isinstance(fastkafka._application.app.AIOKafkaConsumer, InMemoryConsumer)\n",
    "    assert isinstance(fastkafka._application.app.AIOKafkaProducer, InMemoryProducer)\n",
    "    assert fastkafka._application.app.AIOKafkaConsumer().broker == broker\n",
    "    assert fastkafka._application.app.AIOKafkaProducer().broker == broker\n",
    "    \n",
    "assert fastkafka._application.app.AIOKafkaConsumer == AIOKafkaConsumer\n",
    "assert fastkafka._application.app.AIOKafkaProducer == AIOKafkaProducer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335aea0",
   "metadata": {},
   "source": [
    "## Broker, consumer and producer integration tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4275bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "@asynccontextmanager\n",
    "async def create_consumer_and_producer(\n",
    "    auto_offset_reset: str = \"latest\",\n",
    ") -> AsyncIterator[Tuple[AIOKafkaConsumer, AIOKafkaProducer]]:\n",
    "    consumer = fastkafka._application.app.AIOKafkaConsumer(auto_offset_reset=auto_offset_reset)\n",
    "    producer = fastkafka._application.app.AIOKafkaProducer()\n",
    "\n",
    "    await consumer.start()\n",
    "    await producer.start()\n",
    "\n",
    "    yield (consumer, producer)\n",
    "\n",
    "    await consumer.stop()\n",
    "    await producer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7688d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkEqual(L1, L2):\n",
    "    return len(L1) == len(L2) and sorted(L1) == sorted(L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800d6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert checkEqual([1, 2], [3]) == False\n",
    "assert checkEqual([1, 2, 3], [3, 2, 1]) == True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc21a6e",
   "metadata": {},
   "source": [
    "Sanity check, let's see if the messages are sent to broker and received by the consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90249e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.InMemoryBroker'>.__enter__\n",
      "[INFO] __main__: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "[INFO] __main__: InMemoryBroker starting\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched start() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched start() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['test_topic']\n",
      "[INFO] __main__: AIOKafkaConsumer patched stop() called\n",
      "[INFO] __main__: AIOKafkaProducer patched stop() called\n",
      "<class '__main__.InMemoryBroker'>.__exit__\n",
      "[INFO] __main__: InMemoryBroker stopping\n"
     ]
    }
   ],
   "source": [
    "topic = \"test_topic\"\n",
    "sent_msgs = [f\"msg{i}\".encode(\"UTF-8\") for i in range(320)]\n",
    "\n",
    "with InMemoryBroker([topic]) as broker:\n",
    "    async with create_consumer_and_producer(auto_offset_reset=\"earliest\") as (\n",
    "        consumer,\n",
    "        producer,\n",
    "    ):\n",
    "        [await producer.send(topic, msg) for msg in sent_msgs]\n",
    "        consumer.subscribe([topic])\n",
    "        received = await consumer.getmany()\n",
    "        received_msgs = [msg.value for _, msgs in received.items() for msg in msgs]\n",
    "        data = [msg.value for msg in broker.data[topic]]\n",
    "    assert checkEqual(\n",
    "        received_msgs, sent_msgs\n",
    "    ), f\"{sent_msgs=}\\n{received_msgs=}\\n{data=}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40fa9ed",
   "metadata": {},
   "source": [
    "Check if only subscribed topic messages are received by the consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839a6755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.InMemoryBroker'>.__enter__\n",
      "[INFO] __main__: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "[INFO] __main__: InMemoryBroker starting\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched start() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched start() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['test_topic1']\n",
      "[INFO] __main__: AIOKafkaConsumer patched stop() called\n",
      "[INFO] __main__: AIOKafkaProducer patched stop() called\n",
      "<class '__main__.InMemoryBroker'>.__exit__\n",
      "[INFO] __main__: InMemoryBroker stopping\n"
     ]
    }
   ],
   "source": [
    "topic1 = \"test_topic1\"\n",
    "topic2 = \"test_topic2\"\n",
    "sent_msgs_1 = [(f\"msg{i}\" + topic1).encode(\"UTF-8\") for i in range(32)]\n",
    "sent_msgs_2 = [(f\"msg{i}\" + topic2).encode(\"UTF-8\") for i in range(32)]\n",
    "\n",
    "with InMemoryBroker([topic1, topic2]) as broker:\n",
    "    async with create_consumer_and_producer(auto_offset_reset=\"earliest\") as (\n",
    "        consumer,\n",
    "        producer,\n",
    "    ):\n",
    "        [await producer.send(topic1, msg) for msg in sent_msgs_1]\n",
    "        [await producer.send(topic2, msg) for msg in sent_msgs_2]\n",
    "\n",
    "        consumer.subscribe([topic1])\n",
    "        received = await consumer.getmany()\n",
    "        received_msgs = [msg.value for _, msgs in received.items() for msg in msgs]\n",
    "\n",
    "    assert checkEqual(sent_msgs_1, received_msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb1c5c5",
   "metadata": {},
   "source": [
    "Check if msgs are received only after subscribing when auto_offset_reset is set to \"latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6bba51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.InMemoryBroker'>.__enter__\n",
      "[INFO] __main__: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "[INFO] __main__: InMemoryBroker starting\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched start() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched start() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['test_topic']\n",
      "[INFO] __main__: AIOKafkaConsumer patched stop() called\n",
      "[INFO] __main__: AIOKafkaProducer patched stop() called\n",
      "<class '__main__.InMemoryBroker'>.__exit__\n",
      "[INFO] __main__: InMemoryBroker stopping\n"
     ]
    }
   ],
   "source": [
    "topic = \"test_topic\"\n",
    "sent_msgs_before = [f\"msg{i}\".encode(\"UTF-8\") for i in range(32)]\n",
    "sent_msgs_after = [f\"msg{i}\".encode(\"UTF-8\") for i in range(32, 64)]\n",
    "\n",
    "with InMemoryBroker([topic]) as broker:\n",
    "    async with create_consumer_and_producer() as (consumer, producer):\n",
    "        [await producer.send(topic, msg) for msg in sent_msgs_before]\n",
    "\n",
    "        consumer.subscribe([topic])\n",
    "        [await producer.send(topic, msg) for msg in sent_msgs_after]\n",
    "        received = await consumer.getmany()\n",
    "        received_msgs = [msg.value for _, msgs in received.items() for msg in msgs]\n",
    "\n",
    "    assert checkEqual(sent_msgs_after, received_msgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
