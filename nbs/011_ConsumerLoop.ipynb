{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dfbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _components.aiokafka_consumer_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "from asyncio import iscoroutinefunction  # do not use the version from inspect\n",
    "from typing import *\n",
    "\n",
    "import anyio\n",
    "import asyncer\n",
    "from aiokafka import AIOKafkaConsumer\n",
    "from aiokafka.structs import ConsumerRecord, TopicPartition\n",
    "from anyio.streams.memory import MemoryObjectReceiveStream\n",
    "from pydantic import BaseModel\n",
    "from pydantic.main  import ModelMetaclass\n",
    "\n",
    "from fastkafka._components.logger import get_logger\n",
    "from fastkafka._components.meta import delegates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a446cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from datetime import datetime, timedelta\n",
    "from unittest.mock import AsyncMock, MagicMock, Mock, call, patch\n",
    "\n",
    "from pydantic import Field, HttpUrl, NonNegativeInt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from fastkafka._components.logger import supress_timestamps\n",
    "from fastkafka._helpers import produce_messages\n",
    "from fastkafka.testing import ApacheKafkaBroker, true_after\n",
    "\n",
    "from fastkafka._components.encoder.json import json_decoder\n",
    "from fastkafka._components.encoder.avro import avro_decoder, avro_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "# allows async calls in notebooks\n",
    "\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53542175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92feb585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: ok\n"
     ]
    }
   ],
   "source": [
    "supress_timestamps()\n",
    "logger = get_logger(__name__, level=20)\n",
    "logger.info(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf0d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMessage(BaseModel):\n",
    "    url: HttpUrl = Field(..., example=\"http://www.acme.com\", description=\"Url example\")\n",
    "    port: NonNegativeInt = Field(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_consumer_record(topic: str, partition: int, msg: BaseModel):\n",
    "    record = ConsumerRecord(\n",
    "        topic=topic,\n",
    "        partition=partition,\n",
    "        offset=0,\n",
    "        timestamp=0,\n",
    "        timestamp_type=0,\n",
    "        key=None,\n",
    "        value=msg.json().encode(\"utf-8\")\n",
    "        if hasattr(msg, \"json\")\n",
    "        else msg.encode(\"utf-8\"),\n",
    "        checksum=0,\n",
    "        serialized_key_size=0,\n",
    "        serialized_value_size=0,\n",
    "        headers=[],\n",
    "    )\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf847b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _create_safe_callback(\n",
    "    callback: Callable[[BaseModel], Awaitable[None]]\n",
    ") -> Callable[[BaseModel], Awaitable[None]]:\n",
    "    \"\"\"\n",
    "    Wraps an async callback into a safe callback that catches any Exception and loggs them as warnings\n",
    "\n",
    "    Params:\n",
    "        callback: async callable that will be wrapped into a safe callback\n",
    "\n",
    "    Returns:\n",
    "        Wrapped callback into a safe callback that handles exceptions\n",
    "    \"\"\"\n",
    "\n",
    "    async def _safe_callback(\n",
    "        msg: BaseModel,\n",
    "        callback: Callable[[BaseModel], Awaitable[None]] = callback,\n",
    "    ) -> None:\n",
    "        try:\n",
    "            await callback(msg)\n",
    "        except Exception as e:\n",
    "            logger.warning(\n",
    "                f\"_safe_callback(): exception caugth {e.__repr__()} while awaiting '{callback}({msg})'\"\n",
    "            )\n",
    "\n",
    "    return _safe_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b218a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if callback is called when wrapped\n",
    "\n",
    "example_msg = \"Example msg\"\n",
    "callback = AsyncMock()\n",
    "safe_callback = _create_safe_callback(callback)\n",
    "\n",
    "await safe_callback(f\"{example_msg}\")\n",
    "\n",
    "callback.assert_awaited_once_with(f\"{example_msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if exception is caught and logged when callback is called and throws an exception\n",
    "\n",
    "with patch.object(logger, \"warning\") as mock:\n",
    "    example_msg = \"Example msg\"\n",
    "    exception = Exception(\"\")\n",
    "\n",
    "    callback = AsyncMock()\n",
    "    callback.side_effect = exception\n",
    "    safe_callback = _create_safe_callback(callback)\n",
    "\n",
    "    await safe_callback(f\"{example_msg}\")\n",
    "\n",
    "    callback.assert_awaited_once_with(f\"{example_msg}\")\n",
    "    mock.assert_called_once_with(\n",
    "        f\"_safe_callback(): exception caugth {exception.__repr__()} while awaiting '{callback}({example_msg})'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd1a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _prepare_callback(\n",
    "    callback: Callable[[BaseModel], Union[None, Awaitable[None]]]\n",
    ") -> Callable[[BaseModel], Awaitable[None]]:\n",
    "    \"\"\"\n",
    "    Prepares a callback to be used in the consumer loop.\n",
    "        1. If callback is sync, asyncify it\n",
    "        2. Wrap the callback into a safe callback for exception handling\n",
    "\n",
    "    Params:\n",
    "        callback: async callable that will be prepared for use in consumer\n",
    "\n",
    "    Returns:\n",
    "        Prepared callback\n",
    "    \"\"\"\n",
    "    async_callback: Callable[[BaseModel], Awaitable[None]] = (\n",
    "        callback if iscoroutinefunction(callback) else asyncer.asyncify(callback)  # type: ignore\n",
    "    )\n",
    "    return _create_safe_callback(async_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e996f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if callback is called when wrapped\n",
    "\n",
    "for is_async in [False, True]:\n",
    "    example_msg = \"Example msg\"\n",
    "    callback = AsyncMock() if is_async else Mock()\n",
    "    prepared_callback = _prepare_callback(callback)\n",
    "\n",
    "    await prepared_callback(f\"{example_msg}\")\n",
    "\n",
    "    callback.assert_called_once_with(f\"{example_msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0977bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def _stream_msgs(  # type: ignore\n",
    "    msgs: Dict[TopicPartition, bytes],\n",
    "    send_stream: anyio.streams.memory.MemoryObjectSendStream[Any],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Decodes and streams the message and topic to the send_stream.\n",
    "\n",
    "    Params:\n",
    "        msgs:\n",
    "        send_stream:\n",
    "    \"\"\"\n",
    "    for topic_partition, topic_msgs in msgs.items():\n",
    "        topic = topic_partition.topic\n",
    "        try:\n",
    "            await send_stream.send(topic_msgs)\n",
    "        except Exception as e:\n",
    "            logger.warning(\n",
    "                f\"_stream_msgs(): Unexpected exception '{e.__repr__()}' caught and ignored for topic='{topic_partition.topic}', partition='{topic_partition.partition}' and messages: {topic_msgs!r}\"\n",
    "            )\n",
    "\n",
    "\n",
    "def _decode_streamed_msgs(  # type: ignore\n",
    "    msgs: List[ConsumerRecord], msg_type: BaseModel\n",
    ") -> List[BaseModel]:\n",
    "    decoded_msgs = [msg_type.parse_raw(msg.value.decode(\"utf-8\")) for msg in msgs]\n",
    "    return decoded_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335aa93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: one msg, one topic\n",
    "\n",
    "with patch(\"anyio.streams.memory.MemoryObjectSendStream.send\") as mock:\n",
    "    send_stream, receive_stream = anyio.create_memory_object_stream()\n",
    "\n",
    "    topic = \"topic_0\"\n",
    "    partition = 0\n",
    "    topic_part_0_0 = TopicPartition(topic, partition)\n",
    "    msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "    record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "    await _stream_msgs(\n",
    "        msgs={topic_part_0_0: [record]},\n",
    "        send_stream=send_stream,\n",
    "    )\n",
    "\n",
    "    mock.assert_called_once()\n",
    "    mock.assert_has_calls([call([record])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ecc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check different topics\n",
    "\n",
    "# Two msg, two topics, send called twice with each topic\n",
    "\n",
    "with patch(\"anyio.streams.memory.MemoryObjectSendStream.send\") as mock:\n",
    "    send_stream, receive_stream = anyio.create_memory_object_stream()\n",
    "\n",
    "    topic_partitions = [(\"topic_0\", 0), (\"topic_1\", 0)]\n",
    "\n",
    "    msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "    msgs = {\n",
    "        TopicPartition(topic, partition): [\n",
    "            create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "        ]\n",
    "        for topic, partition in topic_partitions\n",
    "    }\n",
    "\n",
    "    await _stream_msgs(\n",
    "        msgs=msgs,\n",
    "        send_stream=send_stream,\n",
    "    )\n",
    "\n",
    "    assert mock.call_count == 2\n",
    "\n",
    "    mock.assert_has_calls([call(msg) for msg in msgs.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3fa870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check multiple msgs in same topic\n",
    "\n",
    "# Two msg, one topic, send called twice for same topic\n",
    "\n",
    "with patch(\"anyio.streams.memory.MemoryObjectSendStream.send\") as mock:\n",
    "    send_stream, receive_stream = anyio.create_memory_object_stream()\n",
    "\n",
    "    topic_partitions = [(\"topic_0\", 0)]\n",
    "\n",
    "    msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "    record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "    msgs = {\n",
    "        TopicPartition(topic, partition): [\n",
    "            create_consumer_record(topic=topic, partition=partition, msg=msg),\n",
    "            create_consumer_record(topic=topic, partition=partition, msg=msg),\n",
    "        ]\n",
    "        for topic, partition in topic_partitions\n",
    "    }\n",
    "\n",
    "    await _stream_msgs(\n",
    "        msgs=msgs,\n",
    "        send_stream=send_stream,\n",
    "    )\n",
    "\n",
    "    mock.assert_has_calls([call(msg) for msg in msgs.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403988a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check multiple partitions\n",
    "\n",
    "# Two msg, one topic, differenct partitions, send called twice for same topic\n",
    "\n",
    "with patch(\"anyio.streams.memory.MemoryObjectSendStream.send\") as mock:\n",
    "    send_stream, receive_stream = anyio.create_memory_object_stream()\n",
    "\n",
    "    topic_partitions = [(\"topic_0\", 0), (\"topic_0\", 1)]\n",
    "\n",
    "    msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "    msgs = {\n",
    "        TopicPartition(topic, partition): [\n",
    "            create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "        ]\n",
    "        for topic, partition in topic_partitions\n",
    "    }\n",
    "    record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "    await _stream_msgs(\n",
    "        msgs=msgs,\n",
    "        send_stream=send_stream,\n",
    "    )\n",
    "\n",
    "    mock.assert_has_calls([call(msg) for msg in msgs.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df02ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def _streamed_records(\n",
    "    receive_stream: MemoryObjectReceiveStream,\n",
    ") -> AsyncGenerator[Any, Any]:\n",
    "    async for records_per_topic in receive_stream:\n",
    "        for records in records_per_topic:\n",
    "            for record in records:\n",
    "                yield record\n",
    "\n",
    "\n",
    "@delegates(AIOKafkaConsumer.getmany)\n",
    "async def _aiokafka_consumer_loop(  # type: ignore\n",
    "    consumer: AIOKafkaConsumer,\n",
    "    *,\n",
    "    topic: str,\n",
    "    decoder_fn: Callable[[bytes, ModelMetaclass], Any],\n",
    "    callback: Callable[[BaseModel], Union[None, Awaitable[None]]],\n",
    "    max_buffer_size: int = 100_000,\n",
    "    msg_type: Type[BaseModel],\n",
    "    is_shutting_down_f: Callable[[], bool],\n",
    "    **kwargs: Any,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Consumer loop for infinite pooling of the AIOKafka consumer for new messages. Calls consumer.getmany()\n",
    "    and after the consumer return messages or times out, messages are decoded and streamed to defined callback.\n",
    "\n",
    "    Params:\n",
    "        topic: Topic to subscribe\n",
    "        decoder_fn: Function to decode the messages consumed from the topic\n",
    "        callbacks: Dict of callbacks mapped to their respective topics\n",
    "        timeout_ms: Time to timeut the getmany request by the consumer\n",
    "        max_buffer_size: Maximum number of unconsumed messages in the callback buffer\n",
    "        msg_types: Dict of message types mapped to their respective topics\n",
    "        is_shutting_down_f: Function for controlling the shutdown of consumer loop\n",
    "    \"\"\"\n",
    "\n",
    "    prepared_callback = _prepare_callback(callback)\n",
    "\n",
    "    async def process_message_callback(\n",
    "        receive_stream: MemoryObjectReceiveStream[Any],\n",
    "        callback: Callable[[BaseModel], Awaitable[None]] = prepared_callback,\n",
    "        msg_type: Type[BaseModel] = msg_type,\n",
    "        topic: str = topic,\n",
    "        decoder_fn: Callable[[bytes, ModelMetaclass], Any] = decoder_fn,\n",
    "    ) -> None:\n",
    "        async with receive_stream:\n",
    "            try:\n",
    "                async for record in _streamed_records(receive_stream):\n",
    "                    try:\n",
    "                        msg = record.value\n",
    "#                         decoded_msg = msg_type.parse_raw(msg.decode(\"utf-8\"))\n",
    "                        decoded_msg = decoder_fn(msg, msg_type)\n",
    "                        await callback(decoded_msg)\n",
    "                    except Exception as e:\n",
    "                        logger.warning(\n",
    "                            f\"process_message_callback(): Unexpected exception '{e.__repr__()}' caught and ignored for topic='{topic}' and message: {msg}\"\n",
    "                        )\n",
    "            except Exception as e:\n",
    "                logger.warning(\n",
    "                    f\"process_message_callback(): Unexpected exception '{e.__repr__()}' caught and ignored for topic='{topic}'\"\n",
    "                )\n",
    "\n",
    "    send_stream, receive_stream = anyio.create_memory_object_stream(\n",
    "        max_buffer_size=max_buffer_size\n",
    "    )\n",
    "\n",
    "    async with anyio.create_task_group() as tg:\n",
    "        tg.start_soon(process_message_callback, receive_stream)\n",
    "        async with send_stream:\n",
    "            while not is_shutting_down_f():\n",
    "                msgs = await consumer.getmany(**kwargs)\n",
    "                try:\n",
    "                    await send_stream.send(msgs.values())\n",
    "                except Exception as e:\n",
    "                    logger.warning(\n",
    "                        f\"_aiokafka_consumer_loop(): Unexpected exception '{e}' caught and ignored for messages: {msgs}\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a60f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_shutting_down_f(mock_func: Mock, num_calls: int = 1) -> Callable[[], bool]:\n",
    "    def _is_shutting_down_f():\n",
    "        return mock_func.call_count == num_calls\n",
    "\n",
    "    return _is_shutting_down_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77397e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"topic_0\"\n",
    "partition = 0\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "mock_consumer = MagicMock()\n",
    "msgs = {TopicPartition(topic, 0): [record]}\n",
    "\n",
    "f = asyncio.Future()\n",
    "f.set_result(msgs)\n",
    "mock_consumer.configure_mock(**{\"getmany.return_value\": f})\n",
    "mock_callback = Mock()\n",
    "\n",
    "\n",
    "for is_async in [True, False]:\n",
    "    await _aiokafka_consumer_loop(\n",
    "        consumer=mock_consumer,\n",
    "        topic=topic,\n",
    "        decoder_fn=json_decoder,\n",
    "        max_buffer_size=100,\n",
    "        timeout_ms=10,\n",
    "        callback=asyncer.asyncify(mock_callback) if is_async else mock_callback,\n",
    "        msg_type=MyMessage,\n",
    "        is_shutting_down_f=is_shutting_down_f(mock_consumer.getmany),\n",
    "    )\n",
    "\n",
    "    assert mock_consumer.getmany.call_count == 1\n",
    "    mock_callback.assert_called_once_with(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9e6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] __main__: _safe_callback(): exception caugth Exception('') while awaiting '<function asyncify.<locals>.wrapper>(url=HttpUrl('http://www.acme.com', ) port=22)'\n",
      "[WARNING] __main__: _safe_callback(): exception caugth Exception('') while awaiting '<function asyncify.<locals>.wrapper>(url=HttpUrl('http://www.acme.com', ) port=22)'\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: exception in callback recovery\n",
    "# Two msg, one topic, process_f called twice even tough it throws\n",
    "\n",
    "topic = \"topic_0\"\n",
    "partition = 0\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "num_msgs = 2\n",
    "\n",
    "mock_consumer = MagicMock()\n",
    "msgs = {TopicPartition(topic, 0): [record, record]}\n",
    "\n",
    "f = asyncio.Future()\n",
    "f.set_result(msgs)\n",
    "\n",
    "mock_consumer.configure_mock(**{\"getmany.return_value\": f})\n",
    "mock_callback = Mock()\n",
    "\n",
    "exception = Exception(\"\")\n",
    "mock_callback.side_effect = exception\n",
    "\n",
    "for is_async in [True, False]:\n",
    "    await _aiokafka_consumer_loop(\n",
    "        consumer=mock_consumer,\n",
    "        topic=topic,\n",
    "        decoder_fn=json_decoder,\n",
    "        max_buffer_size=100,\n",
    "        timeout_ms=1,\n",
    "        callback=asyncer.asyncify(mock_callback) if is_async else mock_callback,\n",
    "        msg_type=MyMessage,\n",
    "        is_shutting_down_f=is_shutting_down_f(mock_consumer.getmany, num_calls=1),\n",
    "    )\n",
    "\n",
    "    assert mock_callback.call_count == num_msgs, mock_callback.call_count\n",
    "    mock_callback.assert_has_calls([call(msg), call(msg)])\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afe654a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: malformed msgs\n",
    "# One msg of wrong type, two normal msg, one topic, process_f called twice\n",
    "\n",
    "topic = \"topic_0\"\n",
    "partition = 0\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "correct_record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "faulty_record = create_consumer_record(topic=topic, partition=partition, msg=\"Wrong!\")\n",
    "\n",
    "mock_consumer = MagicMock()\n",
    "msgs = {TopicPartition(topic, 0): [faulty_record, correct_record, correct_record]}\n",
    "\n",
    "mock_consumer.configure_mock(**{\"getmany.return_value\": f})\n",
    "mock_callback = Mock()\n",
    "\n",
    "exception = Exception(\"\")\n",
    "callback.side_effect = exception\n",
    "\n",
    "for is_async in [True, False]:\n",
    "    await _aiokafka_consumer_loop(\n",
    "        consumer=mock_consumer,\n",
    "        topic=topic,\n",
    "        decoder_fn=json_decoder,\n",
    "        max_buffer_size=100,\n",
    "        timeout_ms=10,\n",
    "        callback=asyncer.asyncify(mock_callback) if is_async else mock_callback,\n",
    "        msg_type=MyMessage,\n",
    "        is_shutting_down_f=is_shutting_down_f(mock_consumer.getmany),\n",
    "    )\n",
    "\n",
    "    assert mock_consumer.getmany.call_count == 1\n",
    "    mock_callback.assert_has_calls([call(msg), call(msg)])\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46031397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def sanitize_kafka_config(**kwargs: Any) -> Dict[str, Any]:\n",
    "    \"\"\"Sanitize Kafka config\"\"\"\n",
    "    return {k: \"*\" * len(v) if \"pass\" in k.lower() else v for k, v in kwargs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa2ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"bootstrap_servers\": \"whatever.cloud:9092\",\n",
    "    \"auto_offset_reset\": \"earliest\",\n",
    "    \"security_protocol\": \"SASL_SSL\",\n",
    "    \"sasl_mechanism\": \"PLAIN\",\n",
    "    \"sasl_plain_username\": \"username\",\n",
    "    \"sasl_plain_password\": \"password\",\n",
    "    \"ssl_context\": \"something\",\n",
    "}\n",
    "\n",
    "assert sanitize_kafka_config(**kwargs)[\"sasl_plain_password\"] == \"********\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ba3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@delegates(AIOKafkaConsumer)\n",
    "@delegates(_aiokafka_consumer_loop, keep=True)\n",
    "async def aiokafka_consumer_loop(\n",
    "    topic: str,\n",
    "    decoder_fn: Callable[[bytes, ModelMetaclass], Any],\n",
    "    *,\n",
    "    timeout_ms: int = 100,\n",
    "    max_buffer_size: int = 100_000,\n",
    "    callback: Callable[[BaseModel], Union[None, Awaitable[None]]],\n",
    "    msg_type: Type[BaseModel],\n",
    "    is_shutting_down_f: Callable[[], bool],\n",
    "    **kwargs: Any,\n",
    ") -> None:\n",
    "    \"\"\"Consumer loop for infinite pooling of the AIOKafka consumer for new messages. Creates and starts AIOKafkaConsumer\n",
    "    and runs _aio_kafka_consumer loop fo infinite poling of the consumer for new messages.\n",
    "\n",
    "    Args:\n",
    "        topic: name of the topic to subscribe to\n",
    "        decoder_fn: Function to decode the messages consumed from the topic\n",
    "        callback: callback function to be called after decoding and parsing a consumed message\n",
    "        timeout_ms: Time to timeut the getmany request by the consumer\n",
    "        max_buffer_size: Maximum number of unconsumed messages in the callback buffer\n",
    "        msg_type: Type with `parse_json` method used for parsing a decoded message\n",
    "        is_shutting_down_f: Function for controlling the shutdown of consumer loop\n",
    "    \"\"\"\n",
    "    logger.info(f\"aiokafka_consumer_loop() starting...\")\n",
    "    try:\n",
    "        consumer = AIOKafkaConsumer(\n",
    "            **kwargs,\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"aiokafka_consumer_loop(): Consumer created using the following parameters: {sanitize_kafka_config(**kwargs)}\"\n",
    "        )\n",
    "\n",
    "        await consumer.start()\n",
    "        logger.info(\"aiokafka_consumer_loop(): Consumer started.\")\n",
    "        consumer.subscribe([topic])\n",
    "        logger.info(\"aiokafka_consumer_loop(): Consumer subscribed.\")\n",
    "\n",
    "        try:\n",
    "            await _aiokafka_consumer_loop(\n",
    "                consumer=consumer,\n",
    "                topic=topic,\n",
    "                decoder_fn=decoder_fn,\n",
    "                max_buffer_size=max_buffer_size,\n",
    "                timeout_ms=timeout_ms,\n",
    "                callback=callback,\n",
    "                msg_type=msg_type,\n",
    "                is_shutting_down_f=is_shutting_down_f,\n",
    "            )\n",
    "        finally:\n",
    "            await consumer.stop()\n",
    "            logger.info(f\"aiokafka_consumer_loop(): Consumer stopped.\")\n",
    "            logger.info(f\"aiokafka_consumer_loop() finished.\")\n",
    "    except Exception as e:\n",
    "        logger.error(\n",
    "            f\"aiokafka_consumer_loop(): unexpected exception raised: '{e.__repr__()}'\"\n",
    "        )\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89d47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad8d1635c85481d9339f1af2058fad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "producing to 'test_topic':   0%|          | 0/9178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: aiokafka_consumer_loop() starting...\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. \n",
      "[INFO] __main__: msgs_received=1000\n",
      "[INFO] __main__: msgs_received=2000\n",
      "[INFO] __main__: msgs_received=3000\n",
      "[INFO] __main__: msgs_received=4000\n",
      "[INFO] __main__: msgs_received=5000\n",
      "[INFO] __main__: msgs_received=6000\n",
      "[INFO] __main__: msgs_received=7000\n",
      "[INFO] __main__: msgs_received=8000\n",
      "[INFO] __main__: msgs_received=9000\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] __main__: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 606654...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 606654 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 606282...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 606282 terminated.\n"
     ]
    }
   ],
   "source": [
    "topic = \"test_topic\"\n",
    "msgs_sent = 9178\n",
    "msgs = [\n",
    "    MyMessage(url=\"http://www.ai.com\", port=port).json().encode(\"utf-8\")\n",
    "    for port in range(msgs_sent)\n",
    "]\n",
    "msgs_received = 0\n",
    "\n",
    "\n",
    "async def count_msg(msg: MyMessage):\n",
    "    global msgs_received\n",
    "    msgs_received = msgs_received + 1\n",
    "    if msgs_received % 1000 == 0:\n",
    "        logger.info(f\"{msgs_received=}\")\n",
    "\n",
    "\n",
    "async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:\n",
    "    await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)\n",
    "    await aiokafka_consumer_loop(\n",
    "        topic=topic,\n",
    "        decoder_fn=json_decoder,\n",
    "        auto_offset_reset=\"earliest\",\n",
    "        callback=count_msg,\n",
    "        msg_type=MyMessage,\n",
    "        is_shutting_down_f=true_after(2),\n",
    "        bootstrap_servers=bootstrap_server,\n",
    "    )\n",
    "\n",
    "    assert msgs_sent == msgs_received, f\"{msgs_sent} != {msgs_received}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ea86a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef430783b7c845ea84f7d530d5401457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "producing to 'test_topic':   0%|          | 0/9178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: aiokafka_consumer_loop() starting...\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. \n",
      "[INFO] __main__: msgs_received=1000\n",
      "[INFO] __main__: msgs_received=2000\n",
      "[INFO] __main__: msgs_received=3000\n",
      "[INFO] __main__: msgs_received=4000\n",
      "[INFO] __main__: msgs_received=5000\n",
      "[INFO] __main__: msgs_received=6000\n",
      "[INFO] __main__: msgs_received=7000\n",
      "[INFO] __main__: msgs_received=8000\n",
      "[INFO] __main__: msgs_received=9000\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] __main__: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 607858...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 607858 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 607486...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 607486 terminated.\n"
     ]
    }
   ],
   "source": [
    "# Test with avro_decoder\n",
    "\n",
    "topic = \"test_topic\"\n",
    "msgs_sent = 9178\n",
    "msgs = [\n",
    "    avro_encoder(MyMessage(url=\"http://www.ai.com\", port=port))\n",
    "    for port in range(msgs_sent)\n",
    "]\n",
    "msgs_received = 0\n",
    "\n",
    "\n",
    "async def count_msg(msg: MyMessage):\n",
    "    global msgs_received\n",
    "    msgs_received = msgs_received + 1\n",
    "    if msgs_received % 1000 == 0:\n",
    "        logger.info(f\"{msgs_received=}\")\n",
    "\n",
    "\n",
    "async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:\n",
    "    await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)\n",
    "    await aiokafka_consumer_loop(\n",
    "        topic=topic,\n",
    "        decoder_fn=avro_decoder,\n",
    "        auto_offset_reset=\"earliest\",\n",
    "        callback=count_msg,\n",
    "        msg_type=MyMessage,\n",
    "        is_shutting_down_f=true_after(2),\n",
    "        bootstrap_servers=bootstrap_server,\n",
    "    )\n",
    "\n",
    "    assert msgs_sent == msgs_received, f\"{msgs_sent} != {msgs_received}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9d9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578f4a347fe648a7a2b3899d656c782e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "producing to 'test_topic':   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd00a4f8895e42b6bc5e25012a991b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "consuming messages:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: aiokafka_consumer_loop() starting...\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. \n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] __main__: aiokafka_consumer_loop() finished.\n",
      "Messages processed: 50,000\n",
      "Time              : 0.72 s\n",
      "Throughput.       : 69,657 msg/s\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 609063...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 609063 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 608691...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 608691 terminated.\n"
     ]
    }
   ],
   "source": [
    "topic = \"test_topic\"\n",
    "msgs_sent = 500_00\n",
    "msgs = [\n",
    "    MyMessage(url=\"http://www.ai.com\", port=port).json().encode(\"utf-8\")\n",
    "    for port in range(msgs_sent)\n",
    "]\n",
    "\n",
    "\n",
    "async def count_msg(msg: MyMessage):\n",
    "    pbar.update(1)\n",
    "\n",
    "\n",
    "def _is_shutting_down_f():\n",
    "    return pbar.n >= pbar.total\n",
    "\n",
    "\n",
    "async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:\n",
    "    await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)\n",
    "    with tqdm(total=msgs_sent, desc=\"consuming messages\") as _pbar:\n",
    "        global pbar\n",
    "        pbar = _pbar\n",
    "\n",
    "        start = datetime.now()\n",
    "        await aiokafka_consumer_loop(\n",
    "            topic=topic,\n",
    "            decoder_fn=json_decoder,\n",
    "            auto_offset_reset=\"earliest\",\n",
    "            callback=count_msg,\n",
    "            msg_type=MyMessage,\n",
    "            is_shutting_down_f=_is_shutting_down_f,\n",
    "            bootstrap_servers=bootstrap_server,\n",
    "        )\n",
    "        t = (datetime.now() - start) / timedelta(seconds=1)\n",
    "        thrp = pbar.n / t\n",
    "\n",
    "        print(f\"Messages processed: {pbar.n:,d}\")\n",
    "        print(f\"Time              : {t:.2f} s\")\n",
    "        print(f\"Throughput.       : {thrp:,.0f} msg/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ada17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9f82accabd4a0ca5843436e9d16af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "producing to 'test_topic':   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6c9f0d51124e009347923663ef72b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "consuming messages:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: aiokafka_consumer_loop() starting...\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. \n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] __main__: aiokafka_consumer_loop() finished.\n",
      "Messages processed: 50,000\n",
      "Time              : 1.62 s\n",
      "Throughput.       : 30,849 msg/s\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 610265...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 610265 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 609892...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 609892 terminated.\n"
     ]
    }
   ],
   "source": [
    "# Test with avro_decoder\n",
    "\n",
    "topic = \"test_topic\"\n",
    "msgs_sent = 500_00\n",
    "msgs = [\n",
    "    avro_encoder(MyMessage(url=\"http://www.ai.com\", port=port))\n",
    "    for port in range(msgs_sent)\n",
    "]\n",
    "\n",
    "\n",
    "async def count_msg(msg: MyMessage):\n",
    "    pbar.update(1)\n",
    "\n",
    "\n",
    "def _is_shutting_down_f():\n",
    "    return pbar.n >= pbar.total\n",
    "\n",
    "\n",
    "async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:\n",
    "    await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)\n",
    "    with tqdm(total=msgs_sent, desc=\"consuming messages\") as _pbar:\n",
    "        global pbar\n",
    "        pbar = _pbar\n",
    "\n",
    "        start = datetime.now()\n",
    "        await aiokafka_consumer_loop(\n",
    "            topic=topic,\n",
    "            decoder_fn=avro_decoder,\n",
    "            auto_offset_reset=\"earliest\",\n",
    "            callback=count_msg,\n",
    "            msg_type=MyMessage,\n",
    "            is_shutting_down_f=_is_shutting_down_f,\n",
    "            bootstrap_servers=bootstrap_server,\n",
    "        )\n",
    "        t = (datetime.now() - start) / timedelta(seconds=1)\n",
    "        thrp = pbar.n / t\n",
    "\n",
    "        print(f\"Messages processed: {pbar.n:,d}\")\n",
    "        print(f\"Time              : {t:.2f} s\")\n",
    "        print(f\"Throughput.       : {thrp:,.0f} msg/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e37ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
